{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_predict",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilgarad/stock_predict/blob/master/jupyter_notebooks/stock_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IE2ZxTCyE9OF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "8876a59f-08c2-4a09-c887-947a60e969eb"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dToXl7clWOOQ",
        "colab_type": "code",
        "outputId": "9cfa315a-c60a-4d72-9233-34bb35d5acab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/stock_predict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/stock_predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ed2G1SFgVe_1",
        "colab_type": "code",
        "outputId": "f95a8579-3158-4bd6-94c7-dd0399286a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "cell_type": "code",
      "source": [
        "ls -ltr"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 3067434\n",
            "-rw------- 1 root root 3141039662 Sep  1 13:15 2018_07_28_stock_data_all_new.csv\n",
            "drwx------ 2 root root       4096 Nov  8 12:59 \u001b[0m\u001b[01;34mstock_data_2000to2017\u001b[0m/\n",
            "drwx------ 2 root root       4096 Nov  8 23:46 \u001b[01;34mstock_data_2018\u001b[0m/\n",
            "drwx------ 2 root root       4096 Nov 17 05:04 \u001b[01;34mstock_predict\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lSDHZqSPcgVK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import"
      ]
    },
    {
      "metadata": {
        "id": "SF8TS5andJFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/stock_predict/stock_predict')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-M6EuwC6dOqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from src.hparams import HParams\n",
        "from src.train import Train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DdUhCCYMb-z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 전처리 미리하기"
      ]
    },
    {
      "metadata": {
        "id": "I8W9Wj92dm6_",
        "colab_type": "code",
        "outputId": "aaa0a36a-d560-4135-de8d-c59239fb3c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# input_path = '/content/drive/stock_predict/stock_data'\n",
        "input_path = '/content/drive/stock_predict/stock_data_2017to2018'\n",
        "output_path = '/content/drive/stock_predict/20seq_data_2017to2018'\n",
        "# new\n",
        "dataset = DataSet(data_path=input_path, data_status=2, output_path=output_path, label_price=0, sequence_length=20, mode=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading stock data by compnay name\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vfKa_scGcFBJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ]
    },
    {
      "metadata": {
        "id": "SP5r964vdnAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sp = Train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MR5j4sWEhflt",
        "colab_type": "code",
        "outputId": "6c6cf476-09f9-4f9b-a237-6a01007de3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/My Drive/stock_predict/stock_data_2000to2017'\n",
        "output_path = '/content/gdrive/My Drive/stock_predict/models/rnn_2000to2017'\n",
        "test_path = '/content/gdrive/My Drive/stock_predict/stock_data_2018'\n",
        "hparams = HParams()\n",
        "hparams.update(num_labels=2)\n",
        "hparams.update(attention_type=2)\n",
        "sp.train(data_path=data_path, output_path=output_path, test_path=test_path,\n",
        "model_name='rnn', hparams=hparams)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of layers: 1\n",
            "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
            "Loading stock data by compnay name\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P2KmJdLwD7dx",
        "colab_type": "code",
        "outputId": "c0de5125-8b91-43ce-e911-466c2ccb483c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "print(listdir('/content/drive/stock_predict/20seq_data_2017/labelled_data_0'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['x_y0.npy', 'x_y1.npy', 'x_y2.npy', 'x_y3.npy', 'x_y4.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkLer4bWy9WR",
        "colab_type": "code",
        "outputId": "6706ab53-9060-4ce2-a20f-158b50ec1dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/stock_predict/20seq_data_2017to2018/labelled_data_0/x_y0.npy'\n",
        "output_path = '/content/drive/stock_predict/models/20seq_model_2017to2018_h100'\n",
        "sp.training(data_path=data_path, output_path=output_path, use_gpu=True, rnn_type='gru', mode=0, epochs=20, batch_size=1000, \n",
        "           sequence_length=20, train_test_ratio=0.02, use_bidirectional=True, dim_hidden=100,  feature_length=7,\n",
        "            label_term=10, learning_rate=0.01, num_layers=1, data_status=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading stock data by compnay name\n",
            "769355\n",
            "769355\n",
            "Label 0 and num of data: 5849\n",
            "Label 1 and num of data: 121689\n",
            "Label 2 and num of data: 4336045\n",
            "Label 3 and num of data: 10679743\n",
            "Label 4 and num of data: 208176\n",
            "Label 5 and num of data: 35598\n",
            "Label Length: 6\n",
            "Num of layers: 1\n",
            "batch size: Tensor(\"strided_slice:0\", shape=(), dtype=int32, device=/device:GPU:0)\n",
            "[global_step-500] duration: 47s train_loss: 0.344987 accuracy: 0.864248\n",
            "[global_step-1000] duration: 46s train_loss: 0.217311 accuracy: 0.911018\n",
            "[global_step-1500] duration: 43s train_loss: 0.210036 accuracy: 0.913493\n",
            "[global_step-2000] duration: 47s train_loss: 0.196536 accuracy: 0.918246\n",
            "[global_step-2500] duration: 46s train_loss: 0.188133 accuracy: 0.921464\n",
            "[global_step-3000] duration: 43s train_loss: 0.185530 accuracy: 0.922434\n",
            "[global_step-3500] duration: 46s train_loss: 0.179499 accuracy: 0.924574\n",
            "[global_step-4000] duration: 47s train_loss: 0.174426 accuracy: 0.926590\n",
            "[global_step-4500] duration: 43s train_loss: 0.173182 accuracy: 0.927036\n",
            "[global_step-5000] duration: 46s train_loss: 0.169960 accuracy: 0.928306\n",
            "[global_step-5000] duration: 41s test_loss: 0.161198 accuracy: 0.906893\n",
            "[global_step-5500] duration: 46s train_loss: 0.165783 accuracy: 0.930057\n",
            "[global_step-6000] duration: 42s train_loss: 0.166335 accuracy: 0.929797\n",
            "[global_step-6500] duration: 48s train_loss: 0.164229 accuracy: 0.930570\n",
            "[global_step-7000] duration: 47s train_loss: 0.162412 accuracy: 0.931326\n",
            "[global_step-7500] duration: 42s train_loss: 0.162297 accuracy: 0.931285\n",
            "[global_step-8000] duration: 46s train_loss: 0.160666 accuracy: 0.931985\n",
            "[global_step-8500] duration: 46s train_loss: 0.159110 accuracy: 0.932437\n",
            "[global_step-9000] duration: 42s train_loss: 0.160171 accuracy: 0.932094\n",
            "[global_step-9500] duration: 46s train_loss: 0.161894 accuracy: 0.931423\n",
            "[global_step-10000] duration: 48s train_loss: 0.164797 accuracy: 0.930478\n",
            "[global_step-10000] duration: 18s test_loss: 0.151868 accuracy: 0.910443\n",
            "[global_step-10500] duration: 43s train_loss: 0.164256 accuracy: 0.930557\n",
            "[global_step-11000] duration: 47s train_loss: 0.160183 accuracy: 0.932142\n",
            "[global_step-11500] duration: 46s train_loss: 0.156555 accuracy: 0.933518\n",
            "[global_step-12000] duration: 43s train_loss: 0.172686 accuracy: 0.927873\n",
            "[global_step-12500] duration: 47s train_loss: 0.185374 accuracy: 0.923556\n",
            "[global_step-13000] duration: 46s train_loss: 0.251495 accuracy: 0.900420\n",
            "[global_step-13500] duration: 41s train_loss: 0.221783 accuracy: 0.910505\n",
            "[global_step-14000] duration: 47s train_loss: 0.198125 accuracy: 0.918547\n",
            "[global_step-14500] duration: 46s train_loss: 0.272815 accuracy: 0.892789\n",
            "[global_step-15000] duration: 43s train_loss: 0.251164 accuracy: 0.900190\n",
            "[global_step-15000] duration: 58s test_loss: 0.217253 accuracy: 0.886340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nMB1451Q9rRw",
        "colab_type": "code",
        "outputId": "1fb967a7-6a3e-49b9-ffab-a0bcb63b26ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/stock_predict/20seq_data_2017to2018/labelled_data_0/x_y0.npy'\n",
        "output_path = '/content/drive/stock_predict/models/20seq_model_2017to2018_h10_001'\n",
        "sp.training(data_path=data_path, output_path=output_path, use_gpu=True, rnn_type='gru', mode=0, epochs=20, batch_size=2000, \n",
        "           sequence_length=20, train_test_ratio=0.02, use_bidirectional=True, dim_hidden=10, feature_length=7,\n",
        "            label_term=10, learning_rate=0.001, num_layers=1, data_status=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading stock data by compnay name\n",
            "769355\n",
            "769355\n",
            "Label 0 and num of data: 5849\n",
            "Label 1 and num of data: 121689\n",
            "Label 2 and num of data: 4336045\n",
            "Label 3 and num of data: 10679743\n",
            "Label 4 and num of data: 208176\n",
            "Label 5 and num of data: 35598\n",
            "Label Length: 6\n",
            "Num of layers: 1\n",
            "batch size: Tensor(\"strided_slice:0\", shape=(), dtype=int32, device=/device:GPU:0)\n",
            "[global_step-500] duration: 55s train_loss: 0.743028 accuracy: 0.692814\n",
            "[global_step-1000] duration: 52s train_loss: 0.645712 accuracy: 0.742343\n",
            "[global_step-1500] duration: 52s train_loss: 0.502905 accuracy: 0.820340\n",
            "[global_step-2000] duration: 55s train_loss: 0.427577 accuracy: 0.856498\n",
            "[global_step-2500] duration: 50s train_loss: 0.404450 accuracy: 0.863389\n",
            "[global_step-3000] duration: 51s train_loss: 0.387697 accuracy: 0.866978\n",
            "[global_step-3500] duration: 54s train_loss: 0.371736 accuracy: 0.869657\n",
            "[global_step-4000] duration: 52s train_loss: 0.362025 accuracy: 0.871054\n",
            "[global_step-4500] duration: 51s train_loss: 0.354656 accuracy: 0.872243\n",
            "[global_step-5000] duration: 56s train_loss: 0.347333 accuracy: 0.873603\n",
            "[global_step-5000] duration: 10s test_loss: 0.262163 accuracy: 0.823130\n",
            "[global_step-5500] duration: 51s train_loss: 0.342415 accuracy: 0.874452\n",
            "[global_step-6000] duration: 51s train_loss: 0.339291 accuracy: 0.875005\n",
            "[global_step-6500] duration: 55s train_loss: 0.334564 accuracy: 0.876124\n",
            "[global_step-7000] duration: 52s train_loss: 0.332172 accuracy: 0.876587\n",
            "[global_step-7500] duration: 52s train_loss: 0.329473 accuracy: 0.877070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D1HlfuZo9rVo",
        "colab_type": "code",
        "outputId": "abe90dc1-5cc4-4ca6-9d7f-951c52aefb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/stock_predict/20seq_data_2017to2018/labelled_data_0/x_y0.npy'\n",
        "output_path = '/content/drive/stock_predict/models/20seq_model_2017to2018_h100_001'\n",
        "sp.training(data_path=data_path, output_path=output_path, use_gpu=True, rnn_type='gru', mode=0, epochs=20, batch_size=1000, \n",
        "           sequence_length=20, train_test_ratio=0.02, use_bidirectional=True, dim_hidden=100,  feature_length=7,\n",
        "            label_term=10, learning_rate=0.001, num_layers=1, data_status=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading stock data by compnay name\n",
            "769355\n",
            "769355\n",
            "Label 0 and num of data: 5849\n",
            "Label 1 and num of data: 121689\n",
            "Label 2 and num of data: 4336045\n",
            "Label 3 and num of data: 10679743\n",
            "Label 4 and num of data: 208176\n",
            "Label 5 and num of data: 35598\n",
            "Label Length: 6\n",
            "Num of layers: 1\n",
            "batch size: Tensor(\"strided_slice:0\", shape=(), dtype=int32, device=/device:GPU:0)\n",
            "[global_step-500] duration: 48s train_loss: 0.517014 accuracy: 0.802547\n",
            "[global_step-1000] duration: 46s train_loss: 0.306392 accuracy: 0.882635\n",
            "[global_step-1500] duration: 44s train_loss: 0.288260 accuracy: 0.888809\n",
            "[global_step-2000] duration: 47s train_loss: 0.259327 accuracy: 0.898087\n",
            "[global_step-2500] duration: 47s train_loss: 0.245319 accuracy: 0.902772\n",
            "[global_step-3000] duration: 43s train_loss: 0.241517 accuracy: 0.903901\n",
            "[global_step-3500] duration: 46s train_loss: 0.232484 accuracy: 0.906783\n",
            "[global_step-4000] duration: 46s train_loss: 0.224993 accuracy: 0.909141\n",
            "[global_step-4500] duration: 42s train_loss: 0.223006 accuracy: 0.909732\n",
            "[global_step-5000] duration: 48s train_loss: 0.217830 accuracy: 0.911449\n",
            "[global_step-5000] duration: 43s test_loss: 0.200504 accuracy: 0.892457\n",
            "[global_step-5500] duration: 47s train_loss: 0.213405 accuracy: 0.913040\n",
            "[global_step-6000] duration: 43s train_loss: 0.211951 accuracy: 0.913381\n",
            "[global_step-6500] duration: 46s train_loss: 0.208426 accuracy: 0.914492\n",
            "[global_step-7000] duration: 46s train_loss: 0.204453 accuracy: 0.915848\n",
            "[global_step-7500] duration: 41s train_loss: 0.204009 accuracy: 0.915967\n",
            "[global_step-8000] duration: 45s train_loss: 0.201151 accuracy: 0.917019\n",
            "[global_step-8500] duration: 46s train_loss: 0.198206 accuracy: 0.918071\n",
            "[global_step-9000] duration: 44s train_loss: 0.197816 accuracy: 0.918156\n",
            "[global_step-9500] duration: 47s train_loss: 0.195231 accuracy: 0.918984\n",
            "[global_step-10000] duration: 46s train_loss: 0.193099 accuracy: 0.919894\n",
            "[global_step-10000] duration: 17s test_loss: 0.177767 accuracy: 0.901164\n",
            "[global_step-10500] duration: 43s train_loss: 0.192261 accuracy: 0.920139\n",
            "[global_step-11000] duration: 45s train_loss: 0.190005 accuracy: 0.920915\n",
            "[global_step-11500] duration: 46s train_loss: 0.187659 accuracy: 0.921721\n",
            "[global_step-12000] duration: 43s train_loss: 0.187248 accuracy: 0.921973\n",
            "[global_step-12500] duration: 46s train_loss: 0.185831 accuracy: 0.922447\n",
            "[global_step-13000] duration: 47s train_loss: 0.182904 accuracy: 0.923651\n",
            "[global_step-13500] duration: 43s train_loss: 0.183412 accuracy: 0.923404\n",
            "[global_step-14000] duration: 45s train_loss: 0.182325 accuracy: 0.923732\n",
            "[global_step-14500] duration: 44s train_loss: 0.181313 accuracy: 0.924253\n",
            "[global_step-15000] duration: 43s train_loss: 0.180667 accuracy: 0.924370\n",
            "[global_step-15000] duration: 58s test_loss: 0.166182 accuracy: 0.905486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-7iW0G3h9rYz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cct--MasrfG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2QtJGQ3xUdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "moC0QJVednFM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IWBAC8FBHE-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1QPMcQCHFJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QB3pz-wTHFF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIR4NgevHFDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JN3LaJvLKj_W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# dataset.py"
      ]
    },
    {
      "metadata": {
        "id": "7HeQX-4SHFCd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "        elif data_status == 1:\n",
        "            # Load sequenced data\n",
        "            data_list = sorted([f for f in listdir(self.data_path)\n",
        "                                     if not isfile(join(self.data_path, f)) and '.DS_Store' not in f])\n",
        "            sequence_data = None\n",
        "            end_data = None\n",
        "\n",
        "            for data in data_list:\n",
        "                all_data = np.load(join(self.data_path, data))\n",
        "                if sequence_data is None:\n",
        "                    sequence_data = all_data[0]  # list of sequence data\n",
        "                    end_data = all_data[1]  # list of end data, will be transformed as label\n",
        "                else:\n",
        "                    sequence_data = np.concatenate([sequence_data, all_data[0]], axis=0)\n",
        "                    end_data = np.concatenate([end_data, all_data[0]], axis=0)\n",
        "\n",
        "            # Make targets (Y)\n",
        "            self.queries, self.labels = PreProcess.make_dataset(sequence_data=sequence_data, end_data=end_data,\n",
        "                                                                output_path=output_path, label_price=label_price,\n",
        "                                                                label_term=label_term, mode=mode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J76eer4zsGLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DataLoader.py"
      ]
    },
    {
      "metadata": {
        "id": "kKYqwp_xJs4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "        if train_test_ratio != 0:\n",
        "            x_train, x_test, y_train, y_test \\\n",
        "                = train_test_split(self.dataset.queries, self.dataset.labels, test_size=train_test_ratio)\n",
        "        else:\n",
        "            x_train = self.dataset.queries\n",
        "            y_train = self.dataset.labels\n",
        "            x_test = None\n",
        "            y_test = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xDfSAUYJyIP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train.py"
      ]
    },
    {
      "metadata": {
        "id": "RVt__MUjHDOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def test(self, model_path, data_path, use_gpu=False, rnn_type='gru', mode=2, batch_size=50,\n",
        "                 sequence_length=10, label_term=10,\n",
        "                 use_bidirectional=False, dim_hidden=10, num_layers=1, data_status=0,\n",
        "                 feature_length=7, attention_type=0):\n",
        "\n",
        "        self.cpu_only = not use_gpu\n",
        "        # print(self.cpu_only)\n",
        "\n",
        "        data_loader = DataLoader(data_path=data_path, mode=mode, sequence_length=sequence_length,\n",
        "                                 train_test_ratio=0, label_term=label_term, output_path=None,\n",
        "                                 data_status=data_status)\n",
        "\n",
        "        label_list = data_loader.label_list\n",
        "        print('Label Length: %i' % (len(label_list)))\n",
        "\n",
        "        model, sess, g = self._model_init(model=self._model, gpu=self.gpu, mode=mode, num_layers=num_layers,\n",
        "                                          rnn_type=rnn_type, feature_length=feature_length,\n",
        "                                          attention_type=attention_type,\n",
        "                                          sequence_length=sequence_length, use_bidirectional=use_bidirectional,\n",
        "                                          dim_hidden=dim_hidden, num_labels=len(label_list), directory=model_path)\n",
        "\n",
        "        t_avg_loss = 0.0\n",
        "        t_avg_accuracy = 0.0\n",
        "        t_batch_iter_max = len(data_loader.dataset) / batch_size + 1\n",
        "\n",
        "        cur_time = datetime.now()\n",
        "        for t_i, (t_data, t_labels) in enumerate(data_loader.batch_loader(data_loader.dataset, batch_size)):\n",
        "            accuracy, logits, loss = sess.run([model.accuracy, model.logits, model.loss],\n",
        "                                              feed_dict={model.x: t_data, model.y: t_labels,\n",
        "                                                         model.dropout_keep_prob: 1.0})\n",
        "\n",
        "            t_avg_loss += float(loss)\n",
        "            t_avg_accuracy += float(accuracy)\n",
        "\n",
        "        t_avg_loss = float(t_avg_loss / t_batch_iter_max)\n",
        "        t_avg_accuracy = float(t_avg_accuracy / t_batch_iter_max)\n",
        "\n",
        "        print('[Test Accuracy] duration: %is test_loss: %f accuracy: %f' % ((datetime.now() - cur_time).seconds,\n",
        "                                                                            t_avg_loss, t_avg_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T34M8EdIJ2dV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# rnn_new.py"
      ]
    },
    {
      "metadata": {
        "id": "hu7Zc5lwJ4AX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "self.pred, self.accuracy, self.correct_count = self.evaluate(self.mode, self.logits, self.y[:, -1])\n",
        "\n",
        "    def evaluate(self, mode, logits, y):\n",
        "        with tf.name_scope('evaluation'):\n",
        "            pred = None\n",
        "\n",
        "            if mode == 0:\n",
        "                pred = tf.argmax(logits, axis=2)\n",
        "                pred = pred[:, -1]\n",
        "                # print(self.y) # Tensor(\"y:0\", shape=(?, 10=sequence_length), dtype=int64, device=/device:CPU:0)\n",
        "            elif mode == 2:\n",
        "                pred = tf.argmax(logits, 1)\n",
        "                # print(self.pred) # Tensor(\"evaluation/ArgMax:0\", shape=(?,), dtype=int64)\n",
        "                # print(self.y) # Tensor(\"y:0\", shape=(?, 1), dtype=int64)\n",
        "\n",
        "\n",
        "            accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y), tf.float32))\n",
        "\n",
        "            correct_count = tf.reduce_sum(tf.to_float(tf.equal(pred, y)), axis=0)\n",
        "\n",
        "        return pred, accuracy, correct_count\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCwFNkkYSVSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "    def build_loss(self, mode, logits, batch_size):\n",
        "        with tf.name_scope('loss'):\n",
        "            # print(self.y)\n",
        "            # print(self.logits)\n",
        "            # self.loss = tf.reduce_mean(\n",
        "            #     tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.logits))\n",
        "            if mode == 0: # Many to many with up / down\n",
        "                weights = tf.ones([batch_size, self.sequence_length])\n",
        "                sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=logits, targets=self.y, weights=weights)\n",
        "                # print(sequence_loss) # Tensor(\"loss/sequence_loss/truediv:0\", shape=(), dtype=float32, device=/device:CPU:0)\n",
        "                loss = tf.reduce_mean(sequence_loss)\n",
        "            elif mode == 1: # Many to many with price\n",
        "                weights = tf.ones([batch_size, self.sequence_length])\n",
        "                sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=logits, targets=self.y, weights=weights)\n",
        "                loss = tf.reduce_mean(sequence_loss)\n",
        "            elif mode == 2: # Many to one with up / down\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=logits))\n",
        "            elif mode == 3: # many to one with price\n",
        "                loss = tf.reduce_mean(\n",
        "                    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=logits))\n",
        "            elif mode == 5: # Multi loss of many to many with up / down + price\n",
        "                weights = tf.ones([batch_size, self.sequence_length])\n",
        "                sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=logits, targets=self.y, weights=weights)\n",
        "                loss1 = tf.reduce_mean(sequence_loss)\n",
        "\n",
        "                weights = tf.ones([batch_size, self.sequence_length])\n",
        "                sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=logits, targets=self.y, weights=weights)\n",
        "                loss2 = tf.reduce_mean(sequence_loss)\n",
        "\n",
        "                loss = tf.group(loss1, loss2)\n",
        "            elif mode == 6: # Multi loss of many to one with up / down + price\n",
        "                loss1 = tf.reduce_mean(\n",
        "                    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=logits))\n",
        "\n",
        "                loss2 = tf.reduce_mean(\n",
        "                    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y, logits=logits))\n",
        "\n",
        "                loss = tf.group(loss1, loss2)\n",
        "            else:\n",
        "                print('Wrong mode option')\n",
        "\n",
        "            return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2l4kpudhJ6Hd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# model_saver.py"
      ]
    },
    {
      "metadata": {
        "id": "9-4mU65BJ8BH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SYE8Es_4EH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ]
    },
    {
      "metadata": {
        "id": "WfoAtcmZ4FoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/44937105/how-to-use-attentionmechanism-with-multirnncell-and-dynamic-decode\n",
        "# https://gist.github.com/ilblackdragon/c92066d9d38b236a21d5a7b729a10f12\n",
        "\n",
        "\n",
        "\n",
        "train_helper = tf.contrib.seq2seq.TrainingHelper(output_embed, output_lengths)\n",
        "    # train_helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n",
        "    #     output_embed, output_lengths, embeddings, 0.3\n",
        "    # )\n",
        "    pred_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
        "        embeddings, start_tokens=tf.to_int32(start_tokens), end_token=1)\n",
        "\n",
        "    def decode(helper, scope, reuse=None):\n",
        "        with tf.variable_scope(scope, reuse=reuse):\n",
        "            attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
        "                num_units=num_units, memory=encoder_outputs,\n",
        "                memory_sequence_length=input_lengths)\n",
        "            cell = tf.contrib.rnn.GRUCell(num_units=num_units)\n",
        "            attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "                cell, attention_mechanism, attention_layer_size=num_units / 2)\n",
        "            out_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
        "                attn_cell, vocab_size, reuse=reuse\n",
        "            )\n",
        "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "                cell=out_cell, helper=helper,\n",
        "                initial_state=out_cell.zero_state(\n",
        "                    dtype=tf.float32, batch_size=batch_size))\n",
        "                #initial_state=encoder_final_state)\n",
        "            outputs = tf.contrib.seq2seq.dynamic_decode(\n",
        "                decoder=decoder, output_time_major=False,\n",
        "                impute_finished=True, maximum_iterations=output_max_length\n",
        "            )\n",
        "            return outputs[0]\n",
        "    train_outputs = decode(train_helper, 'decode')\n",
        "    pred_outputs = decode(pred_helper, 'decode', reuse=True)\n",
        "\n",
        "    tf.identity(train_outputs.sample_id[0], name='train_pred')\n",
        "    weights = tf.to_float(tf.not_equal(train_output[:, :-1], 1))\n",
        "    loss = tf.contrib.seq2seq.sequence_loss(\n",
        "        train_outputs.rnn_output, output, weights=weights)\n",
        "    train_op = layers.optimize_loss(\n",
        "        loss, tf.train.get_global_step(),\n",
        "        optimizer=params.get('optimizer', 'Adam'),\n",
        "        learning_rate=params.get('learning_rate', 0.001),\n",
        "        summaries=['loss', 'learning_rate'])\n",
        "\n",
        "    tf.identity(pred_outputs.sample_id[0], name='predictions')\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=pred_outputs.sample_id,\n",
        "        loss=loss,\n",
        "        train_op=train_op\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHvPepyZ4YMS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MACD"
      ]
    },
    {
      "metadata": {
        "id": "yZwdyaoE4WuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2SJdrWP6C3Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bollinger Bands"
      ]
    },
    {
      "metadata": {
        "id": "8YnNgrc84cA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QxUSnLh6HIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RSI"
      ]
    },
    {
      "metadata": {
        "id": "b-xRuuYZ6FvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yCP-VPfI-8ae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stochastic Oscillator"
      ]
    },
    {
      "metadata": {
        "id": "M5wGBbhp--o_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "piPT3A6I-_bG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Average Movement"
      ]
    },
    {
      "metadata": {
        "id": "CYyDEidH_Cdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x1849BMrcPlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new = pd.DataFrame()\n",
        "\n",
        "for idx, name in enumerate(df.name.unique()):\n",
        "    if idx == 2:\n",
        "        break\n",
        "    df_new = pd.concat([df_new, fnMA(df[df['name'] == name].sort_values(by=['date']).reset_index(drop=True), m_N=[5, 20, 60, 120, 240])])\n",
        "\n",
        "df_new = df_new.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsYFMoJfrNKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 전일비 변경 및 전일대비 퍼센트 변동"
      ]
    },
    {
      "metadata": {
        "id": "bgxtEdihrOY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aqx_HVz1rfi5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ㅁㅁ"
      ]
    },
    {
      "metadata": {
        "id": "T04Gm8RTrqkh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}