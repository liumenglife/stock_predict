{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('d:/myai/stock_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import Train\n",
    "from src.hparams import HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opath_root = 'd:/myai/models_to2017'\n",
    "data_path = 'd:/myai/data/20seq_data_to2016/sequence_data'\n",
    "test_path = 'd:/myai/data/20seq_data_from2017_to2017/sequence_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = Train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to one basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, -20], 1: [-20, -10], 2: [-10, 0], 3: [0, 10], 4: [10, 20], 5: [20, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, -20], 1: [-20, -10], 2: [-10, 0], 3: [0, 10], 4: [10, 20], 5: [20, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 6\n",
      "Num of layers: 1\n",
      "[global_step-500] duration: 96s train_loss: 0.780991 accuracy: 0.649488\n",
      "[global_step-1000] duration: 76s train_loss: 0.771736 accuracy: 0.649608\n",
      "[global_step-1500] duration: 76s train_loss: 0.768187 accuracy: 0.649875\n",
      "[global_step-2000] duration: 76s train_loss: 0.765960 accuracy: 0.649635\n",
      "[global_step-2500] duration: 78s train_loss: 0.764071 accuracy: 0.649522\n",
      "[global_step-3000] duration: 79s train_loss: 0.762466 accuracy: 0.649609\n",
      "[global_step-3500] duration: 77s train_loss: 0.761139 accuracy: 0.649365\n",
      "[global_step-4000] duration: 77s train_loss: 0.759847 accuracy: 0.649062\n",
      "[global_step-4500] duration: 77s train_loss: 0.758747 accuracy: 0.648617\n",
      "[global_step-5000] duration: 77s train_loss: 0.757689 accuracy: 0.648411\n",
      "[global_step-5000] duration: 102s test_loss: 0.675544 accuracy: 0.710405\n",
      "Saving model...\n",
      "[global_step-5500] duration: 79s train_loss: 0.756815 accuracy: 0.648103\n",
      "[global_step-6000] duration: 77s train_loss: 0.755912 accuracy: 0.647914\n",
      "[global_step-6500] duration: 77s train_loss: 0.754958 accuracy: 0.647662\n",
      "[global_step-7000] duration: 77s train_loss: 0.754159 accuracy: 0.647432\n",
      "[global_step-7500] duration: 78s train_loss: 0.753576 accuracy: 0.647210\n",
      "[global_step-8000] duration: 77s train_loss: 0.752752 accuracy: 0.646967\n",
      "[global_step-8500] duration: 78s train_loss: 0.751972 accuracy: 0.646667\n",
      "[global_step-9000] duration: 80s train_loss: 0.751060 accuracy: 0.646489\n",
      "[global_step-9500] duration: 81s train_loss: 0.750252 accuracy: 0.646337\n",
      "[global_step-10000] duration: 76s train_loss: 0.749412 accuracy: 0.646061\n",
      "[global_step-10000] duration: 101s test_loss: 0.653040 accuracy: 0.708254\n",
      "[global_step-10500] duration: 79s train_loss: 0.748705 accuracy: 0.645881\n",
      "[global_step-11000] duration: 125s train_loss: 0.727842 accuracy: 0.634934\n",
      "[global_step-11500] duration: 80s train_loss: 0.730802 accuracy: 0.641837\n",
      "[global_step-12000] duration: 78s train_loss: 0.731854 accuracy: 0.641044\n",
      "[global_step-12500] duration: 80s train_loss: 0.732253 accuracy: 0.640391\n",
      "[global_step-13000] duration: 77s train_loss: 0.731805 accuracy: 0.640177\n",
      "[global_step-13500] duration: 77s train_loss: 0.731553 accuracy: 0.639952\n",
      "[global_step-14000] duration: 77s train_loss: 0.731394 accuracy: 0.639757\n",
      "[global_step-14500] duration: 77s train_loss: 0.731431 accuracy: 0.639465\n",
      "[global_step-15000] duration: 77s train_loss: 0.731124 accuracy: 0.639389\n",
      "[global_step-15000] duration: 99s test_loss: 0.646981 accuracy: 0.706915\n",
      "[global_step-15500] duration: 78s train_loss: 0.730952 accuracy: 0.639384\n",
      "[global_step-16000] duration: 78s train_loss: 0.730808 accuracy: 0.639409\n",
      "[global_step-16500] duration: 79s train_loss: 0.730583 accuracy: 0.639374\n",
      "[global_step-17000] duration: 78s train_loss: 0.730400 accuracy: 0.639089\n",
      "[global_step-17500] duration: 78s train_loss: 0.730286 accuracy: 0.639072\n",
      "[global_step-18000] duration: 80s train_loss: 0.730053 accuracy: 0.639110\n",
      "[global_step-18500] duration: 77s train_loss: 0.730111 accuracy: 0.638947\n",
      "[global_step-19000] duration: 76s train_loss: 0.730060 accuracy: 0.638741\n",
      "[global_step-19500] duration: 78s train_loss: 0.729895 accuracy: 0.638633\n",
      "[global_step-20000] duration: 77s train_loss: 0.729736 accuracy: 0.638551\n",
      "[global_step-20000] duration: 98s test_loss: 0.646488 accuracy: 0.706857\n",
      "[global_step-20500] duration: 80s train_loss: 0.729577 accuracy: 0.638523\n",
      "[global_step-21000] duration: 80s train_loss: 0.729435 accuracy: 0.638483\n",
      "[global_step-21500] duration: 81s train_loss: 0.729216 accuracy: 0.638493\n",
      "[global_step-22000] duration: 142s train_loss: 0.719796 accuracy: 0.642661\n",
      "[global_step-22500] duration: 81s train_loss: 0.723897 accuracy: 0.638121\n",
      "[global_step-23000] duration: 80s train_loss: 0.724027 accuracy: 0.637882\n",
      "[global_step-23500] duration: 80s train_loss: 0.723947 accuracy: 0.637738\n",
      "[global_step-24000] duration: 80s train_loss: 0.724170 accuracy: 0.637407\n",
      "[global_step-24500] duration: 80s train_loss: 0.724249 accuracy: 0.637040\n",
      "[global_step-25000] duration: 80s train_loss: 0.724168 accuracy: 0.636617\n",
      "[global_step-25000] duration: 104s test_loss: 0.645300 accuracy: 0.705775\n",
      "[global_step-25500] duration: 82s train_loss: 0.724187 accuracy: 0.636493\n",
      "[global_step-26000] duration: 81s train_loss: 0.724132 accuracy: 0.636742\n",
      "[global_step-26500] duration: 78s train_loss: 0.723991 accuracy: 0.636614\n",
      "[global_step-27000] duration: 77s train_loss: 0.724034 accuracy: 0.636409\n",
      "[global_step-27500] duration: 78s train_loss: 0.724141 accuracy: 0.636260\n",
      "[global_step-28000] duration: 78s train_loss: 0.724057 accuracy: 0.636319\n",
      "[global_step-28500] duration: 81s train_loss: 0.723900 accuracy: 0.636330\n",
      "[global_step-29000] duration: 79s train_loss: 0.723975 accuracy: 0.636372\n",
      "[global_step-29500] duration: 78s train_loss: 0.724024 accuracy: 0.636263\n",
      "[global_step-30000] duration: 79s train_loss: 0.724137 accuracy: 0.636049\n",
      "[global_step-30000] duration: 103s test_loss: 0.642143 accuracy: 0.702312\n",
      "[global_step-30500] duration: 81s train_loss: 0.724134 accuracy: 0.636094\n",
      "[global_step-31000] duration: 80s train_loss: 0.724009 accuracy: 0.636034\n",
      "[global_step-31500] duration: 81s train_loss: 0.723919 accuracy: 0.635777\n",
      "[global_step-32000] duration: 80s train_loss: 0.723908 accuracy: 0.635561\n",
      "[global_step-32500] duration: 80s train_loss: 0.723829 accuracy: 0.635522\n",
      "[global_step-33000] duration: 142s train_loss: 0.712445 accuracy: 0.643190\n",
      "[global_step-33500] duration: 79s train_loss: 0.722030 accuracy: 0.632365\n",
      "[global_step-34000] duration: 81s train_loss: 0.720772 accuracy: 0.633149\n",
      "[global_step-34500] duration: 81s train_loss: 0.720293 accuracy: 0.633658\n",
      "[global_step-35000] duration: 80s train_loss: 0.720451 accuracy: 0.633545\n",
      "[global_step-35000] duration: 103s test_loss: 0.642480 accuracy: 0.705131\n",
      "[global_step-35500] duration: 81s train_loss: 0.720175 accuracy: 0.634129\n",
      "[global_step-36000] duration: 79s train_loss: 0.719933 accuracy: 0.634198\n",
      "[global_step-36500] duration: 77s train_loss: 0.720040 accuracy: 0.634105\n",
      "[global_step-37000] duration: 76s train_loss: 0.720099 accuracy: 0.634176\n",
      "[global_step-37500] duration: 76s train_loss: 0.720185 accuracy: 0.633942\n",
      "[global_step-38000] duration: 76s train_loss: 0.720123 accuracy: 0.634018\n",
      "[global_step-38500] duration: 76s train_loss: 0.720009 accuracy: 0.634163\n",
      "[global_step-39000] duration: 76s train_loss: 0.720068 accuracy: 0.633812\n",
      "[global_step-39500] duration: 76s train_loss: 0.720180 accuracy: 0.633830\n",
      "[global_step-40000] duration: 76s train_loss: 0.720267 accuracy: 0.633790\n",
      "[global_step-40000] duration: 96s test_loss: 0.641218 accuracy: 0.703502\n",
      "[global_step-40500] duration: 76s train_loss: 0.720166 accuracy: 0.633688\n",
      "[global_step-41000] duration: 76s train_loss: 0.720239 accuracy: 0.633584\n",
      "[global_step-41500] duration: 76s train_loss: 0.720244 accuracy: 0.633383\n",
      "[global_step-42000] duration: 76s train_loss: 0.720145 accuracy: 0.633311\n",
      "[global_step-42500] duration: 76s train_loss: 0.720119 accuracy: 0.633310\n",
      "[global_step-43000] duration: 76s train_loss: 0.720062 accuracy: 0.633138\n",
      "[global_step-43500] duration: 76s train_loss: 0.720049 accuracy: 0.633180\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mto1_norm')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=500,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=1, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 1\n",
      "[global_step-500] duration: 61s train_loss: 0.679159 accuracy: 0.644502\n",
      "[global_step-1000] duration: 45s train_loss: 0.655640 accuracy: 0.658876\n",
      "[global_step-1500] duration: 46s train_loss: 0.647852 accuracy: 0.664082\n",
      "[global_step-2000] duration: 45s train_loss: 0.644058 accuracy: 0.666402\n",
      "[global_step-2500] duration: 45s train_loss: 0.641846 accuracy: 0.667900\n",
      "[global_step-3000] duration: 45s train_loss: 0.640298 accuracy: 0.668871\n",
      "[global_step-3500] duration: 45s train_loss: 0.639189 accuracy: 0.669537\n",
      "[global_step-4000] duration: 45s train_loss: 0.638369 accuracy: 0.670078\n",
      "[global_step-4500] duration: 44s train_loss: 0.637662 accuracy: 0.670582\n",
      "[global_step-5000] duration: 45s train_loss: 0.637184 accuracy: 0.670801\n",
      "[global_step-5000] duration: 43s test_loss: 0.593579 accuracy: 0.722960\n",
      "Saving model...\n",
      "[global_step-5500] duration: 43s train_loss: 0.636974 accuracy: 0.670842\n",
      "[global_step-6000] duration: 41s train_loss: 0.636627 accuracy: 0.671098\n",
      "[global_step-6500] duration: 41s train_loss: 0.636243 accuracy: 0.671440\n",
      "[global_step-7000] duration: 42s train_loss: 0.635919 accuracy: 0.671644\n",
      "[global_step-7500] duration: 44s train_loss: 0.635704 accuracy: 0.671743\n",
      "[global_step-8000] duration: 44s train_loss: 0.635494 accuracy: 0.671874\n",
      "[global_step-8500] duration: 44s train_loss: 0.635311 accuracy: 0.672013\n",
      "[global_step-9000] duration: 44s train_loss: 0.635216 accuracy: 0.672044\n",
      "[global_step-9500] duration: 44s train_loss: 0.635078 accuracy: 0.672130\n",
      "[global_step-10000] duration: 44s train_loss: 0.634937 accuracy: 0.672222\n",
      "[global_step-10000] duration: 43s test_loss: 0.610661 accuracy: 0.720095\n",
      "[global_step-10500] duration: 44s train_loss: 0.634808 accuracy: 0.672330\n",
      "[global_step-11000] duration: 98s train_loss: 0.629634 accuracy: 0.676989\n",
      "[global_step-11500] duration: 45s train_loss: 0.632046 accuracy: 0.674118\n",
      "[global_step-12000] duration: 45s train_loss: 0.632549 accuracy: 0.673621\n",
      "[global_step-12500] duration: 44s train_loss: 0.632610 accuracy: 0.673632\n",
      "[global_step-13000] duration: 44s train_loss: 0.632732 accuracy: 0.673621\n",
      "[global_step-13500] duration: 44s train_loss: 0.632770 accuracy: 0.673524\n",
      "[global_step-14000] duration: 44s train_loss: 0.632668 accuracy: 0.673581\n",
      "[global_step-14500] duration: 44s train_loss: 0.632567 accuracy: 0.673769\n",
      "[global_step-15000] duration: 45s train_loss: 0.632674 accuracy: 0.673584\n",
      "[global_step-15000] duration: 43s test_loss: 0.591880 accuracy: 0.723697\n",
      "Saving model...\n",
      "[global_step-15500] duration: 44s train_loss: 0.632725 accuracy: 0.673606\n",
      "[global_step-16000] duration: 44s train_loss: 0.632735 accuracy: 0.673585\n",
      "[global_step-16500] duration: 44s train_loss: 0.632720 accuracy: 0.673632\n",
      "[global_step-17000] duration: 44s train_loss: 0.632702 accuracy: 0.673645\n",
      "[global_step-17500] duration: 42s train_loss: 0.632729 accuracy: 0.673645\n",
      "[global_step-18000] duration: 41s train_loss: 0.632683 accuracy: 0.673694\n",
      "[global_step-18500] duration: 40s train_loss: 0.632677 accuracy: 0.673712\n",
      "[global_step-19000] duration: 44s train_loss: 0.632647 accuracy: 0.673781\n",
      "[global_step-19500] duration: 44s train_loss: 0.632620 accuracy: 0.673773\n",
      "[global_step-20000] duration: 44s train_loss: 0.632602 accuracy: 0.673768\n",
      "[global_step-20000] duration: 43s test_loss: 0.594817 accuracy: 0.722008\n",
      "[global_step-20500] duration: 44s train_loss: 0.632613 accuracy: 0.673779\n",
      "[global_step-21000] duration: 44s train_loss: 0.632607 accuracy: 0.673797\n",
      "[global_step-21500] duration: 44s train_loss: 0.632599 accuracy: 0.673821\n",
      "[global_step-22000] duration: 92s train_loss: 0.627687 accuracy: 0.679589\n",
      "[global_step-22500] duration: 45s train_loss: 0.632125 accuracy: 0.674922\n",
      "[global_step-23000] duration: 45s train_loss: 0.632712 accuracy: 0.673914\n",
      "[global_step-23500] duration: 45s train_loss: 0.633024 accuracy: 0.673533\n",
      "[global_step-24000] duration: 44s train_loss: 0.633176 accuracy: 0.673600\n",
      "[global_step-24500] duration: 44s train_loss: 0.633439 accuracy: 0.673335\n",
      "[global_step-25000] duration: 45s train_loss: 0.633253 accuracy: 0.673517\n",
      "[global_step-25000] duration: 43s test_loss: 0.616002 accuracy: 0.722010\n",
      "[global_step-25500] duration: 44s train_loss: 0.633066 accuracy: 0.673668\n",
      "[global_step-26000] duration: 43s train_loss: 0.633071 accuracy: 0.673735\n",
      "[global_step-26500] duration: 41s train_loss: 0.633046 accuracy: 0.673821\n",
      "[global_step-27000] duration: 41s train_loss: 0.632912 accuracy: 0.673980\n",
      "[global_step-27500] duration: 43s train_loss: 0.632869 accuracy: 0.674066\n",
      "[global_step-28000] duration: 44s train_loss: 0.632903 accuracy: 0.674017\n",
      "[global_step-28500] duration: 44s train_loss: 0.632905 accuracy: 0.674021\n",
      "[global_step-29000] duration: 44s train_loss: 0.632931 accuracy: 0.673955\n",
      "[global_step-29500] duration: 45s train_loss: 0.632918 accuracy: 0.673956\n",
      "[global_step-30000] duration: 45s train_loss: 0.632893 accuracy: 0.673968\n",
      "[global_step-30000] duration: 43s test_loss: 0.587818 accuracy: 0.723421\n",
      "[global_step-30500] duration: 44s train_loss: 0.632848 accuracy: 0.674047\n",
      "[global_step-31000] duration: 42s train_loss: 0.632841 accuracy: 0.674039\n",
      "[global_step-31500] duration: 41s train_loss: 0.632831 accuracy: 0.674025\n",
      "[global_step-32000] duration: 41s train_loss: 0.632769 accuracy: 0.674136\n",
      "[global_step-32500] duration: 43s train_loss: 0.632759 accuracy: 0.674150\n",
      "[global_step-33000] duration: 103s train_loss: 0.632790 accuracy: 0.672472\n",
      "[global_step-33500] duration: 45s train_loss: 0.632215 accuracy: 0.674746\n",
      "[global_step-34000] duration: 45s train_loss: 0.632825 accuracy: 0.673949\n",
      "[global_step-34500] duration: 44s train_loss: 0.632743 accuracy: 0.673846\n",
      "[global_step-35000] duration: 44s train_loss: 0.632756 accuracy: 0.673727\n",
      "[global_step-35000] duration: 43s test_loss: 0.591532 accuracy: 0.723307\n",
      "[global_step-35500] duration: 44s train_loss: 0.632676 accuracy: 0.673867\n",
      "[global_step-36000] duration: 44s train_loss: 0.632594 accuracy: 0.674050\n",
      "[global_step-36500] duration: 45s train_loss: 0.632576 accuracy: 0.673956\n",
      "[global_step-37000] duration: 44s train_loss: 0.632573 accuracy: 0.674022\n",
      "[global_step-37500] duration: 44s train_loss: 0.632572 accuracy: 0.674085\n",
      "[global_step-38000] duration: 45s train_loss: 0.632549 accuracy: 0.674038\n",
      "[global_step-38500] duration: 45s train_loss: 0.632436 accuracy: 0.674223\n",
      "[global_step-39000] duration: 44s train_loss: 0.632569 accuracy: 0.674018\n",
      "[global_step-39500] duration: 45s train_loss: 0.632546 accuracy: 0.674024\n",
      "[global_step-40000] duration: 45s train_loss: 0.632534 accuracy: 0.674029\n",
      "[global_step-40000] duration: 43s test_loss: 0.589809 accuracy: 0.723461\n",
      "[global_step-40500] duration: 44s train_loss: 0.632529 accuracy: 0.674064\n",
      "[global_step-41000] duration: 44s train_loss: 0.632580 accuracy: 0.673957\n",
      "[global_step-41500] duration: 44s train_loss: 0.632532 accuracy: 0.674031\n",
      "[global_step-42000] duration: 44s train_loss: 0.632510 accuracy: 0.674051\n",
      "[global_step-42500] duration: 45s train_loss: 0.632491 accuracy: 0.674066\n",
      "[global_step-43000] duration: 44s train_loss: 0.632465 accuracy: 0.674104\n",
      "[global_step-43500] duration: 45s train_loss: 0.632501 accuracy: 0.674060\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mto1')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=500,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=1, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 1\n",
      "[global_step-500] duration: 69s train_loss: 0.634603 accuracy: 0.674217\n",
      "[global_step-1000] duration: 51s train_loss: 0.632692 accuracy: 0.674483\n",
      "[global_step-1500] duration: 51s train_loss: 0.631629 accuracy: 0.674848\n",
      "[global_step-2000] duration: 51s train_loss: 0.631051 accuracy: 0.674876\n",
      "[global_step-2500] duration: 51s train_loss: 0.630616 accuracy: 0.674696\n",
      "[global_step-3000] duration: 51s train_loss: 0.630356 accuracy: 0.674504\n",
      "[global_step-3500] duration: 51s train_loss: 0.630152 accuracy: 0.674228\n",
      "[global_step-4000] duration: 51s train_loss: 0.629965 accuracy: 0.673979\n",
      "[global_step-4500] duration: 51s train_loss: 0.629568 accuracy: 0.674114\n",
      "[global_step-5000] duration: 51s train_loss: 0.629374 accuracy: 0.674042\n",
      "[global_step-5000] duration: 131s test_loss: 0.589031 accuracy: 0.722947\n",
      "Saving model...\n",
      "[global_step-5500] duration: 51s train_loss: 0.629085 accuracy: 0.674114\n",
      "[global_step-6000] duration: 51s train_loss: 0.628943 accuracy: 0.673831\n",
      "[global_step-6500] duration: 50s train_loss: 0.628752 accuracy: 0.673699\n",
      "[global_step-7000] duration: 47s train_loss: 0.628665 accuracy: 0.673452\n",
      "[global_step-7500] duration: 47s train_loss: 0.628426 accuracy: 0.673430\n",
      "[global_step-8000] duration: 51s train_loss: 0.628214 accuracy: 0.673340\n",
      "[global_step-8500] duration: 51s train_loss: 0.627775 accuracy: 0.673483\n",
      "[global_step-9000] duration: 51s train_loss: 0.627569 accuracy: 0.673418\n",
      "[global_step-9500] duration: 51s train_loss: 0.627446 accuracy: 0.673316\n",
      "[global_step-10000] duration: 51s train_loss: 0.627166 accuracy: 0.673256\n",
      "[global_step-10000] duration: 131s test_loss: 0.591059 accuracy: 0.718381\n",
      "[global_step-10500] duration: 51s train_loss: 0.626898 accuracy: 0.673223\n",
      "[global_step-11000] duration: 52s train_loss: 0.626658 accuracy: 0.673241\n",
      "[global_step-11500] duration: 51s train_loss: 0.626591 accuracy: 0.672985\n",
      "[global_step-12000] duration: 52s train_loss: 0.626492 accuracy: 0.672783\n",
      "[global_step-12500] duration: 51s train_loss: 0.626310 accuracy: 0.672759\n",
      "[global_step-13000] duration: 51s train_loss: 0.626137 accuracy: 0.672718\n",
      "[global_step-13500] duration: 52s train_loss: 0.625939 accuracy: 0.672687\n",
      "[global_step-14000] duration: 50s train_loss: 0.625817 accuracy: 0.672559\n",
      "[global_step-14500] duration: 47s train_loss: 0.625682 accuracy: 0.672484\n",
      "[global_step-15000] duration: 47s train_loss: 0.625572 accuracy: 0.672347\n",
      "[global_step-15000] duration: 131s test_loss: 0.581141 accuracy: 0.722356\n",
      "[global_step-15500] duration: 51s train_loss: 0.625407 accuracy: 0.672307\n",
      "[global_step-16000] duration: 51s train_loss: 0.625198 accuracy: 0.672294\n",
      "[global_step-16500] duration: 52s train_loss: 0.625055 accuracy: 0.672233\n",
      "[global_step-17000] duration: 51s train_loss: 0.624910 accuracy: 0.672207\n",
      "[global_step-17500] duration: 51s train_loss: 0.624734 accuracy: 0.672244\n",
      "[global_step-18000] duration: 51s train_loss: 0.624583 accuracy: 0.672207\n",
      "[global_step-18500] duration: 52s train_loss: 0.624546 accuracy: 0.672074\n",
      "[global_step-19000] duration: 52s train_loss: 0.624374 accuracy: 0.672024\n",
      "[global_step-19500] duration: 52s train_loss: 0.624252 accuracy: 0.671982\n",
      "[global_step-20000] duration: 52s train_loss: 0.624152 accuracy: 0.671910\n",
      "[global_step-20000] duration: 131s test_loss: 0.577177 accuracy: 0.722799\n",
      "[global_step-20500] duration: 47s train_loss: 0.624031 accuracy: 0.671846\n",
      "[global_step-21000] duration: 47s train_loss: 0.623840 accuracy: 0.671846\n",
      "[global_step-21500] duration: 51s train_loss: 0.623700 accuracy: 0.671782\n",
      "[global_step-22000] duration: 52s train_loss: 0.623586 accuracy: 0.671718\n",
      "[global_step-22500] duration: 52s train_loss: 0.623465 accuracy: 0.671635\n",
      "[global_step-23000] duration: 52s train_loss: 0.623365 accuracy: 0.671561\n",
      "[global_step-23500] duration: 52s train_loss: 0.623237 accuracy: 0.671518\n",
      "[global_step-24000] duration: 52s train_loss: 0.623122 accuracy: 0.671459\n",
      "[global_step-24500] duration: 52s train_loss: 0.623038 accuracy: 0.671359\n",
      "[global_step-25000] duration: 52s train_loss: 0.622937 accuracy: 0.671285\n",
      "[global_step-25000] duration: 131s test_loss: 0.574063 accuracy: 0.721562\n",
      "[global_step-25500] duration: 52s train_loss: 0.622821 accuracy: 0.671197\n",
      "[global_step-26000] duration: 52s train_loss: 0.622744 accuracy: 0.671113\n",
      "[global_step-26500] duration: 52s train_loss: 0.622594 accuracy: 0.671080\n",
      "[global_step-27000] duration: 52s train_loss: 0.622501 accuracy: 0.670970\n",
      "[global_step-27500] duration: 114s train_loss: 0.600751 accuracy: 0.663645\n",
      "[global_step-28000] duration: 47s train_loss: 0.613138 accuracy: 0.667477\n",
      "[global_step-28500] duration: 51s train_loss: 0.613999 accuracy: 0.667109\n",
      "[global_step-29000] duration: 52s train_loss: 0.614732 accuracy: 0.666716\n",
      "[global_step-29500] duration: 52s train_loss: 0.614635 accuracy: 0.666461\n",
      "[global_step-30000] duration: 52s train_loss: 0.614459 accuracy: 0.667158\n",
      "[global_step-30000] duration: 132s test_loss: 0.573446 accuracy: 0.721779\n",
      "[global_step-30500] duration: 47s train_loss: 0.614310 accuracy: 0.667207\n",
      "[global_step-31000] duration: 47s train_loss: 0.614548 accuracy: 0.666684\n",
      "[global_step-31500] duration: 49s train_loss: 0.614470 accuracy: 0.667162\n",
      "[global_step-32000] duration: 52s train_loss: 0.614624 accuracy: 0.667007\n",
      "[global_step-32500] duration: 52s train_loss: 0.614408 accuracy: 0.667118\n",
      "[global_step-33000] duration: 52s train_loss: 0.614407 accuracy: 0.667246\n",
      "[global_step-33500] duration: 52s train_loss: 0.614468 accuracy: 0.667110\n",
      "[global_step-34000] duration: 52s train_loss: 0.614638 accuracy: 0.666945\n",
      "[global_step-34500] duration: 52s train_loss: 0.614569 accuracy: 0.666908\n",
      "[global_step-35000] duration: 52s train_loss: 0.614619 accuracy: 0.666836\n",
      "[global_step-35000] duration: 133s test_loss: 0.571334 accuracy: 0.721267\n",
      "[global_step-35500] duration: 52s train_loss: 0.614627 accuracy: 0.666763\n",
      "[global_step-36000] duration: 52s train_loss: 0.614677 accuracy: 0.666540\n",
      "[global_step-36500] duration: 52s train_loss: 0.614633 accuracy: 0.666534\n",
      "[global_step-37000] duration: 52s train_loss: 0.614564 accuracy: 0.666506\n",
      "[global_step-37500] duration: 52s train_loss: 0.614640 accuracy: 0.666543\n",
      "[global_step-38000] duration: 52s train_loss: 0.614591 accuracy: 0.666612\n",
      "[global_step-38500] duration: 52s train_loss: 0.614576 accuracy: 0.666619\n",
      "[global_step-39000] duration: 52s train_loss: 0.614581 accuracy: 0.666513\n",
      "[global_step-39500] duration: 52s train_loss: 0.614582 accuracy: 0.666510\n",
      "[global_step-40000] duration: 52s train_loss: 0.614525 accuracy: 0.666438\n",
      "[global_step-40000] duration: 133s test_loss: 0.572972 accuracy: 0.720052\n",
      "[global_step-40500] duration: 52s train_loss: 0.614461 accuracy: 0.666458\n",
      "[global_step-41000] duration: 47s train_loss: 0.614428 accuracy: 0.666454\n",
      "[global_step-41500] duration: 47s train_loss: 0.614410 accuracy: 0.666485\n",
      "[global_step-42000] duration: 49s train_loss: 0.614424 accuracy: 0.666411\n",
      "[global_step-42500] duration: 52s train_loss: 0.614408 accuracy: 0.666429\n",
      "[global_step-43000] duration: 51s train_loss: 0.614419 accuracy: 0.666295\n",
      "[global_step-43500] duration: 51s train_loss: 0.614464 accuracy: 0.666233\n",
      "[global_step-44000] duration: 51s train_loss: 0.614448 accuracy: 0.666188\n",
      "[global_step-44500] duration: 51s train_loss: 0.614385 accuracy: 0.666160\n",
      "[global_step-45000] duration: 52s train_loss: 0.614341 accuracy: 0.666208\n",
      "[global_step-45000] duration: 132s test_loss: 0.571742 accuracy: 0.719618\n",
      "[global_step-45500] duration: 52s train_loss: 0.614275 accuracy: 0.666182\n",
      "[global_step-46000] duration: 49s train_loss: 0.614269 accuracy: 0.666076\n",
      "[global_step-46500] duration: 47s train_loss: 0.614208 accuracy: 0.666111\n",
      "[global_step-47000] duration: 47s train_loss: 0.614203 accuracy: 0.666079\n",
      "[global_step-47500] duration: 52s train_loss: 0.614155 accuracy: 0.666066\n",
      "[global_step-48000] duration: 52s train_loss: 0.614089 accuracy: 0.666100\n",
      "[global_step-48500] duration: 52s train_loss: 0.614055 accuracy: 0.666099\n",
      "[global_step-49000] duration: 52s train_loss: 0.614061 accuracy: 0.665994\n",
      "[global_step-49500] duration: 52s train_loss: 0.614041 accuracy: 0.665995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-50000] duration: 52s train_loss: 0.614016 accuracy: 0.665920\n",
      "[global_step-50000] duration: 132s test_loss: 0.570358 accuracy: 0.721962\n",
      "[global_step-50500] duration: 52s train_loss: 0.613955 accuracy: 0.665925\n",
      "[global_step-51000] duration: 51s train_loss: 0.613917 accuracy: 0.665928\n",
      "[global_step-51500] duration: 47s train_loss: 0.613901 accuracy: 0.665882\n",
      "[global_step-52000] duration: 47s train_loss: 0.613876 accuracy: 0.665882\n",
      "[global_step-52500] duration: 50s train_loss: 0.613839 accuracy: 0.665928\n",
      "[global_step-53000] duration: 52s train_loss: 0.613805 accuracy: 0.665908\n",
      "[global_step-53500] duration: 52s train_loss: 0.613753 accuracy: 0.665953\n",
      "[global_step-54000] duration: 52s train_loss: 0.613712 accuracy: 0.665977\n",
      "[global_step-54500] duration: 52s train_loss: 0.613673 accuracy: 0.665962\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l1_mto1_norm')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=200,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=1, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 1\n",
      "[global_step-500] duration: 58s train_loss: 0.673598 accuracy: 0.646547\n",
      "[global_step-1000] duration: 39s train_loss: 0.655927 accuracy: 0.658305\n",
      "[global_step-1500] duration: 39s train_loss: 0.649693 accuracy: 0.662964\n",
      "[global_step-2000] duration: 39s train_loss: 0.646459 accuracy: 0.665450\n",
      "[global_step-2500] duration: 39s train_loss: 0.644922 accuracy: 0.666487\n",
      "[global_step-3000] duration: 39s train_loss: 0.644147 accuracy: 0.666984\n",
      "[global_step-3500] duration: 39s train_loss: 0.643515 accuracy: 0.667163\n",
      "[global_step-4000] duration: 39s train_loss: 0.642825 accuracy: 0.667743\n",
      "[global_step-4500] duration: 39s train_loss: 0.642396 accuracy: 0.667874\n",
      "[global_step-5000] duration: 39s train_loss: 0.641899 accuracy: 0.668384\n",
      "[global_step-5000] duration: 80s test_loss: 0.589897 accuracy: 0.722339\n",
      "Saving model...\n",
      "[global_step-5500] duration: 39s train_loss: 0.641363 accuracy: 0.668976\n",
      "[global_step-6000] duration: 39s train_loss: 0.641002 accuracy: 0.669332\n",
      "[global_step-6500] duration: 39s train_loss: 0.640803 accuracy: 0.669577\n",
      "[global_step-7000] duration: 39s train_loss: 0.640646 accuracy: 0.669696\n",
      "[global_step-7500] duration: 39s train_loss: 0.640496 accuracy: 0.669810\n",
      "[global_step-8000] duration: 39s train_loss: 0.640346 accuracy: 0.670075\n",
      "[global_step-8500] duration: 39s train_loss: 0.640211 accuracy: 0.670166\n",
      "[global_step-9000] duration: 39s train_loss: 0.639997 accuracy: 0.670401\n",
      "[global_step-9500] duration: 35s train_loss: 0.639811 accuracy: 0.670576\n",
      "[global_step-10000] duration: 35s train_loss: 0.639683 accuracy: 0.670649\n",
      "[global_step-10000] duration: 76s test_loss: 0.602366 accuracy: 0.722437\n",
      "Saving model...\n",
      "[global_step-10500] duration: 39s train_loss: 0.639553 accuracy: 0.670809\n",
      "[global_step-11000] duration: 39s train_loss: 0.639487 accuracy: 0.670941\n",
      "[global_step-11500] duration: 39s train_loss: 0.639367 accuracy: 0.671025\n",
      "[global_step-12000] duration: 39s train_loss: 0.639390 accuracy: 0.670975\n",
      "[global_step-12500] duration: 39s train_loss: 0.639302 accuracy: 0.671052\n",
      "[global_step-13000] duration: 39s train_loss: 0.639196 accuracy: 0.671066\n",
      "[global_step-13500] duration: 39s train_loss: 0.639268 accuracy: 0.670981\n",
      "[global_step-14000] duration: 39s train_loss: 0.639206 accuracy: 0.671026\n",
      "[global_step-14500] duration: 39s train_loss: 0.639174 accuracy: 0.671089\n",
      "[global_step-15000] duration: 39s train_loss: 0.639122 accuracy: 0.671123\n",
      "[global_step-15000] duration: 79s test_loss: 0.610213 accuracy: 0.722146\n",
      "[global_step-15500] duration: 38s train_loss: 0.639063 accuracy: 0.671195\n",
      "[global_step-16000] duration: 35s train_loss: 0.639058 accuracy: 0.671172\n",
      "[global_step-16500] duration: 35s train_loss: 0.638987 accuracy: 0.671237\n",
      "[global_step-17000] duration: 35s train_loss: 0.638978 accuracy: 0.671248\n",
      "[global_step-17500] duration: 39s train_loss: 0.638926 accuracy: 0.671328\n",
      "[global_step-18000] duration: 39s train_loss: 0.638875 accuracy: 0.671391\n",
      "[global_step-18500] duration: 39s train_loss: 0.638836 accuracy: 0.671454\n",
      "[global_step-19000] duration: 39s train_loss: 0.638830 accuracy: 0.671453\n",
      "[global_step-19500] duration: 39s train_loss: 0.638781 accuracy: 0.671505\n",
      "[global_step-20000] duration: 39s train_loss: 0.638748 accuracy: 0.671530\n",
      "[global_step-20000] duration: 79s test_loss: 0.588903 accuracy: 0.722736\n",
      "Saving model...\n",
      "[global_step-20500] duration: 40s train_loss: 0.638724 accuracy: 0.671599\n",
      "[global_step-21000] duration: 39s train_loss: 0.638700 accuracy: 0.671645\n",
      "[global_step-21500] duration: 39s train_loss: 0.638692 accuracy: 0.671674\n",
      "[global_step-22000] duration: 39s train_loss: 0.638721 accuracy: 0.671652\n",
      "[global_step-22500] duration: 39s train_loss: 0.638724 accuracy: 0.671643\n",
      "[global_step-23000] duration: 39s train_loss: 0.638729 accuracy: 0.671649\n",
      "[global_step-23500] duration: 39s train_loss: 0.638669 accuracy: 0.671685\n",
      "[global_step-24000] duration: 39s train_loss: 0.638637 accuracy: 0.671737\n",
      "[global_step-24500] duration: 39s train_loss: 0.638616 accuracy: 0.671749\n",
      "[global_step-25000] duration: 39s train_loss: 0.638631 accuracy: 0.671750\n",
      "[global_step-25000] duration: 79s test_loss: 0.587875 accuracy: 0.723117\n",
      "Saving model...\n",
      "[global_step-25500] duration: 39s train_loss: 0.638623 accuracy: 0.671776\n",
      "[global_step-26000] duration: 39s train_loss: 0.638650 accuracy: 0.671719\n",
      "[global_step-26500] duration: 39s train_loss: 0.638630 accuracy: 0.671749\n",
      "[global_step-27000] duration: 39s train_loss: 0.638606 accuracy: 0.671787\n",
      "[global_step-27500] duration: 92s train_loss: 0.637820 accuracy: 0.673692\n",
      "[global_step-28000] duration: 39s train_loss: 0.639289 accuracy: 0.672858\n",
      "[global_step-28500] duration: 35s train_loss: 0.639411 accuracy: 0.671580\n",
      "[global_step-29000] duration: 35s train_loss: 0.639558 accuracy: 0.671366\n",
      "[global_step-29500] duration: 35s train_loss: 0.639280 accuracy: 0.671466\n",
      "[global_step-30000] duration: 38s train_loss: 0.639531 accuracy: 0.671285\n",
      "[global_step-30000] duration: 79s test_loss: 0.613004 accuracy: 0.719976\n",
      "[global_step-30500] duration: 39s train_loss: 0.639131 accuracy: 0.671635\n",
      "[global_step-31000] duration: 40s train_loss: 0.638732 accuracy: 0.672168\n",
      "[global_step-31500] duration: 39s train_loss: 0.638616 accuracy: 0.672304\n",
      "[global_step-32000] duration: 39s train_loss: 0.638690 accuracy: 0.672127\n",
      "[global_step-32500] duration: 39s train_loss: 0.638706 accuracy: 0.671969\n",
      "[global_step-33000] duration: 39s train_loss: 0.638672 accuracy: 0.672076\n",
      "[global_step-33500] duration: 39s train_loss: 0.638493 accuracy: 0.672258\n",
      "[global_step-34000] duration: 39s train_loss: 0.638583 accuracy: 0.672103\n",
      "[global_step-34500] duration: 39s train_loss: 0.638563 accuracy: 0.672197\n",
      "[global_step-35000] duration: 39s train_loss: 0.638531 accuracy: 0.672244\n",
      "[global_step-35000] duration: 79s test_loss: 0.617094 accuracy: 0.722634\n",
      "[global_step-35500] duration: 39s train_loss: 0.638538 accuracy: 0.672191\n",
      "[global_step-36000] duration: 38s train_loss: 0.638578 accuracy: 0.672104\n",
      "[global_step-36500] duration: 35s train_loss: 0.638593 accuracy: 0.672027\n",
      "[global_step-37000] duration: 35s train_loss: 0.638626 accuracy: 0.671977\n",
      "[global_step-37500] duration: 35s train_loss: 0.638640 accuracy: 0.671986\n",
      "[global_step-38000] duration: 38s train_loss: 0.638602 accuracy: 0.672072\n",
      "[global_step-38500] duration: 39s train_loss: 0.638573 accuracy: 0.672069\n",
      "[global_step-39000] duration: 39s train_loss: 0.638607 accuracy: 0.672015\n",
      "[global_step-39500] duration: 39s train_loss: 0.638618 accuracy: 0.672033\n",
      "[global_step-40000] duration: 39s train_loss: 0.638538 accuracy: 0.672112\n",
      "[global_step-40000] duration: 79s test_loss: 0.587695 accuracy: 0.723466\n",
      "Saving model...\n",
      "[global_step-40500] duration: 39s train_loss: 0.638476 accuracy: 0.672190\n",
      "[global_step-41000] duration: 39s train_loss: 0.638362 accuracy: 0.672319\n",
      "[global_step-41500] duration: 39s train_loss: 0.638361 accuracy: 0.672324\n",
      "[global_step-42000] duration: 39s train_loss: 0.638346 accuracy: 0.672314\n",
      "[global_step-42500] duration: 39s train_loss: 0.638314 accuracy: 0.672324\n",
      "[global_step-43000] duration: 39s train_loss: 0.638347 accuracy: 0.672308\n",
      "[global_step-43500] duration: 38s train_loss: 0.638381 accuracy: 0.672260\n",
      "[global_step-44000] duration: 35s train_loss: 0.638376 accuracy: 0.672254\n",
      "[global_step-44500] duration: 35s train_loss: 0.638376 accuracy: 0.672239\n",
      "[global_step-45000] duration: 35s train_loss: 0.638350 accuracy: 0.672211\n",
      "[global_step-45000] duration: 79s test_loss: 0.592234 accuracy: 0.723025\n",
      "[global_step-45500] duration: 39s train_loss: 0.638329 accuracy: 0.672193\n",
      "[global_step-46000] duration: 39s train_loss: 0.638298 accuracy: 0.672233\n",
      "[global_step-46500] duration: 39s train_loss: 0.638270 accuracy: 0.672263\n",
      "[global_step-47000] duration: 39s train_loss: 0.638218 accuracy: 0.672341\n",
      "[global_step-47500] duration: 39s train_loss: 0.638221 accuracy: 0.672366\n",
      "[global_step-48000] duration: 39s train_loss: 0.638239 accuracy: 0.672348\n",
      "[global_step-48500] duration: 39s train_loss: 0.638248 accuracy: 0.672373\n",
      "[global_step-49000] duration: 39s train_loss: 0.638205 accuracy: 0.672409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-49500] duration: 39s train_loss: 0.638227 accuracy: 0.672387\n",
      "[global_step-50000] duration: 39s train_loss: 0.638214 accuracy: 0.672404\n",
      "[global_step-50000] duration: 76s test_loss: 0.602854 accuracy: 0.723300\n",
      "[global_step-50500] duration: 39s train_loss: 0.638192 accuracy: 0.672474\n",
      "[global_step-51000] duration: 39s train_loss: 0.638204 accuracy: 0.672474\n",
      "[global_step-51500] duration: 39s train_loss: 0.638209 accuracy: 0.672470\n",
      "[global_step-52000] duration: 39s train_loss: 0.638203 accuracy: 0.672473\n",
      "[global_step-52500] duration: 39s train_loss: 0.638192 accuracy: 0.672467\n",
      "[global_step-53000] duration: 39s train_loss: 0.638193 accuracy: 0.672484\n",
      "[global_step-53500] duration: 39s train_loss: 0.638217 accuracy: 0.672450\n",
      "[global_step-54000] duration: 39s train_loss: 0.638192 accuracy: 0.672490\n",
      "[global_step-54500] duration: 39s train_loss: 0.638227 accuracy: 0.672434\n",
      "[global_step-55000] duration: 96s train_loss: 0.647953 accuracy: 0.667159\n",
      "[global_step-55000] duration: 79s test_loss: 0.595408 accuracy: 0.723442\n",
      "[global_step-55500] duration: 39s train_loss: 0.638587 accuracy: 0.672721\n",
      "[global_step-56000] duration: 37s train_loss: 0.638513 accuracy: 0.672703\n",
      "[global_step-56500] duration: 35s train_loss: 0.638187 accuracy: 0.672747\n",
      "[global_step-57000] duration: 35s train_loss: 0.638008 accuracy: 0.672423\n",
      "[global_step-57500] duration: 35s train_loss: 0.637600 accuracy: 0.672809\n",
      "[global_step-58000] duration: 39s train_loss: 0.638071 accuracy: 0.672621\n",
      "[global_step-58500] duration: 39s train_loss: 0.637856 accuracy: 0.672803\n",
      "[global_step-59000] duration: 39s train_loss: 0.637733 accuracy: 0.672843\n",
      "[global_step-59500] duration: 39s train_loss: 0.637917 accuracy: 0.672676\n",
      "[global_step-60000] duration: 39s train_loss: 0.637640 accuracy: 0.673018\n",
      "[global_step-60000] duration: 79s test_loss: 0.592417 accuracy: 0.721594\n",
      "[global_step-60500] duration: 39s train_loss: 0.637391 accuracy: 0.673326\n",
      "[global_step-61000] duration: 39s train_loss: 0.637403 accuracy: 0.673365\n",
      "[global_step-61500] duration: 39s train_loss: 0.637529 accuracy: 0.673180\n",
      "[global_step-62000] duration: 39s train_loss: 0.637548 accuracy: 0.673100\n",
      "[global_step-62500] duration: 39s train_loss: 0.637592 accuracy: 0.673004\n",
      "[global_step-63000] duration: 39s train_loss: 0.637643 accuracy: 0.672921\n",
      "[global_step-63500] duration: 39s train_loss: 0.637601 accuracy: 0.672955\n",
      "[global_step-64000] duration: 39s train_loss: 0.637646 accuracy: 0.672859\n",
      "[global_step-64500] duration: 36s train_loss: 0.637601 accuracy: 0.672884\n",
      "[global_step-65000] duration: 35s train_loss: 0.637735 accuracy: 0.672695\n",
      "[global_step-65000] duration: 75s test_loss: 0.591026 accuracy: 0.723074\n",
      "[global_step-65500] duration: 39s train_loss: 0.637766 accuracy: 0.672677\n",
      "[global_step-66000] duration: 39s train_loss: 0.637708 accuracy: 0.672691\n",
      "[global_step-66500] duration: 39s train_loss: 0.637617 accuracy: 0.672786\n",
      "[global_step-67000] duration: 39s train_loss: 0.637638 accuracy: 0.672745\n",
      "[global_step-67500] duration: 39s train_loss: 0.637681 accuracy: 0.672708\n",
      "[global_step-68000] duration: 39s train_loss: 0.637685 accuracy: 0.672731\n",
      "[global_step-68500] duration: 39s train_loss: 0.637643 accuracy: 0.672753\n",
      "[global_step-69000] duration: 39s train_loss: 0.637654 accuracy: 0.672726\n",
      "[global_step-69500] duration: 39s train_loss: 0.637576 accuracy: 0.672830\n",
      "[global_step-70000] duration: 39s train_loss: 0.637588 accuracy: 0.672856\n",
      "[global_step-70000] duration: 79s test_loss: 0.619900 accuracy: 0.720879\n",
      "[global_step-70500] duration: 39s train_loss: 0.637543 accuracy: 0.672923\n",
      "[global_step-71000] duration: 35s train_loss: 0.637544 accuracy: 0.672910\n",
      "[global_step-71500] duration: 35s train_loss: 0.637590 accuracy: 0.672900\n",
      "[global_step-72000] duration: 35s train_loss: 0.637588 accuracy: 0.672925\n",
      "[global_step-72500] duration: 37s train_loss: 0.637566 accuracy: 0.672969\n",
      "[global_step-73000] duration: 39s train_loss: 0.637586 accuracy: 0.672925\n",
      "[global_step-73500] duration: 39s train_loss: 0.637580 accuracy: 0.672923\n",
      "[global_step-74000] duration: 39s train_loss: 0.637543 accuracy: 0.672959\n",
      "[global_step-74500] duration: 39s train_loss: 0.637539 accuracy: 0.672950\n",
      "[global_step-75000] duration: 39s train_loss: 0.637533 accuracy: 0.672954\n",
      "[global_step-75000] duration: 79s test_loss: 0.595709 accuracy: 0.723559\n",
      "Saving model...\n",
      "[global_step-75500] duration: 39s train_loss: 0.637632 accuracy: 0.672847\n",
      "[global_step-76000] duration: 39s train_loss: 0.637633 accuracy: 0.672855\n",
      "[global_step-76500] duration: 39s train_loss: 0.637580 accuracy: 0.672917\n",
      "[global_step-77000] duration: 39s train_loss: 0.637564 accuracy: 0.672912\n",
      "[global_step-77500] duration: 39s train_loss: 0.637571 accuracy: 0.672898\n",
      "[global_step-78000] duration: 39s train_loss: 0.637578 accuracy: 0.672889\n",
      "[global_step-78500] duration: 39s train_loss: 0.637549 accuracy: 0.672910\n",
      "[global_step-79000] duration: 39s train_loss: 0.637578 accuracy: 0.672874\n",
      "[global_step-79500] duration: 39s train_loss: 0.637581 accuracy: 0.672872\n",
      "[global_step-80000] duration: 39s train_loss: 0.637537 accuracy: 0.672933\n",
      "[global_step-80000] duration: 79s test_loss: 0.588985 accuracy: 0.723348\n",
      "[global_step-80500] duration: 39s train_loss: 0.637537 accuracy: 0.672931\n",
      "[global_step-81000] duration: 39s train_loss: 0.637541 accuracy: 0.672933\n",
      "[global_step-81500] duration: 40s train_loss: 0.637563 accuracy: 0.672918\n",
      "[global_step-82000] duration: 39s train_loss: 0.637581 accuracy: 0.672888\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l1_mto1')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=200,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=1, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 2\n",
      "[global_step-500] duration: 113s train_loss: 0.635796 accuracy: 0.673793\n",
      "[global_step-1000] duration: 85s train_loss: 0.633173 accuracy: 0.674942\n",
      "[global_step-1500] duration: 89s train_loss: 0.631856 accuracy: 0.675394\n",
      "[global_step-2000] duration: 95s train_loss: 0.631477 accuracy: 0.674914\n",
      "[global_step-2500] duration: 95s train_loss: 0.630881 accuracy: 0.675025\n",
      "[global_step-3000] duration: 95s train_loss: 0.630339 accuracy: 0.675184\n",
      "[global_step-3500] duration: 95s train_loss: 0.629746 accuracy: 0.675493\n",
      "[global_step-4000] duration: 95s train_loss: 0.629570 accuracy: 0.675260\n",
      "[global_step-4500] duration: 86s train_loss: 0.629261 accuracy: 0.675295\n",
      "[global_step-5000] duration: 89s train_loss: 0.629167 accuracy: 0.674992\n",
      "[global_step-5000] duration: 198s test_loss: 0.596868 accuracy: 0.723080\n",
      "Saving model...\n",
      "[global_step-5500] duration: 95s train_loss: 0.628903 accuracy: 0.674919\n",
      "[global_step-6000] duration: 95s train_loss: 0.628639 accuracy: 0.674982\n",
      "[global_step-6500] duration: 95s train_loss: 0.628490 accuracy: 0.674924\n",
      "[global_step-7000] duration: 85s train_loss: 0.628364 accuracy: 0.674825\n",
      "[global_step-7500] duration: 90s train_loss: 0.628221 accuracy: 0.674656\n",
      "[global_step-8000] duration: 95s train_loss: 0.628076 accuracy: 0.674530\n",
      "[global_step-8500] duration: 95s train_loss: 0.627964 accuracy: 0.674412\n",
      "[global_step-9000] duration: 95s train_loss: 0.627803 accuracy: 0.674268\n",
      "[global_step-9500] duration: 95s train_loss: 0.627674 accuracy: 0.674267\n",
      "[global_step-10000] duration: 95s train_loss: 0.627555 accuracy: 0.674189\n",
      "[global_step-10000] duration: 199s test_loss: 0.588185 accuracy: 0.722573\n",
      "[global_step-10500] duration: 95s train_loss: 0.627360 accuracy: 0.674197\n",
      "[global_step-11000] duration: 95s train_loss: 0.627245 accuracy: 0.674063\n",
      "[global_step-11500] duration: 95s train_loss: 0.627052 accuracy: 0.674059\n",
      "[global_step-12000] duration: 95s train_loss: 0.626880 accuracy: 0.674052\n",
      "[global_step-12500] duration: 95s train_loss: 0.626741 accuracy: 0.673973\n",
      "[global_step-13000] duration: 84s train_loss: 0.626657 accuracy: 0.673834\n",
      "[global_step-13500] duration: 91s train_loss: 0.626569 accuracy: 0.673731\n",
      "[global_step-14000] duration: 95s train_loss: 0.626479 accuracy: 0.673560\n",
      "[global_step-14500] duration: 95s train_loss: 0.626367 accuracy: 0.673544\n",
      "[global_step-15000] duration: 95s train_loss: 0.626251 accuracy: 0.673483\n",
      "[global_step-15000] duration: 199s test_loss: 0.580570 accuracy: 0.723434\n",
      "Saving model...\n",
      "[global_step-15500] duration: 85s train_loss: 0.626098 accuracy: 0.673462\n",
      "[global_step-16000] duration: 92s train_loss: 0.626040 accuracy: 0.673346\n",
      "[global_step-16500] duration: 95s train_loss: 0.625908 accuracy: 0.673344\n",
      "[global_step-17000] duration: 95s train_loss: 0.625774 accuracy: 0.673306\n",
      "[global_step-17500] duration: 95s train_loss: 0.625658 accuracy: 0.673291\n",
      "[global_step-18000] duration: 95s train_loss: 0.625607 accuracy: 0.673165\n",
      "[global_step-18500] duration: 95s train_loss: 0.625534 accuracy: 0.673088\n",
      "[global_step-19000] duration: 95s train_loss: 0.625411 accuracy: 0.673068\n",
      "[global_step-19500] duration: 95s train_loss: 0.625313 accuracy: 0.673018\n",
      "[global_step-20000] duration: 95s train_loss: 0.625235 accuracy: 0.672901\n",
      "[global_step-20000] duration: 198s test_loss: 0.579204 accuracy: 0.722391\n",
      "[global_step-20500] duration: 90s train_loss: 0.625163 accuracy: 0.672844\n",
      "[global_step-21000] duration: 85s train_loss: 0.625031 accuracy: 0.672858\n",
      "[global_step-21500] duration: 95s train_loss: 0.624965 accuracy: 0.672790\n",
      "[global_step-22000] duration: 95s train_loss: 0.624859 accuracy: 0.672753\n",
      "[global_step-22500] duration: 95s train_loss: 0.624747 accuracy: 0.672767\n",
      "[global_step-23000] duration: 95s train_loss: 0.624629 accuracy: 0.672775\n",
      "[global_step-23500] duration: 95s train_loss: 0.624580 accuracy: 0.672661\n",
      "[global_step-24000] duration: 95s train_loss: 0.624533 accuracy: 0.672586\n",
      "[global_step-24500] duration: 95s train_loss: 0.624424 accuracy: 0.672590\n",
      "[global_step-25000] duration: 86s train_loss: 0.624404 accuracy: 0.672478\n",
      "[global_step-25000] duration: 194s test_loss: 0.576809 accuracy: 0.723367\n",
      "[global_step-25500] duration: 95s train_loss: 0.624287 accuracy: 0.672417\n",
      "[global_step-26000] duration: 95s train_loss: 0.624196 accuracy: 0.672359\n",
      "[global_step-26500] duration: 95s train_loss: 0.624148 accuracy: 0.672310\n",
      "[global_step-27000] duration: 95s train_loss: 0.624057 accuracy: 0.672230\n",
      "[global_step-27500] duration: 141s train_loss: 0.621666 accuracy: 0.659779\n",
      "[global_step-28000] duration: 95s train_loss: 0.618067 accuracy: 0.670880\n",
      "[global_step-28500] duration: 95s train_loss: 0.618024 accuracy: 0.670662\n",
      "[global_step-29000] duration: 95s train_loss: 0.618081 accuracy: 0.669718\n",
      "[global_step-29500] duration: 95s train_loss: 0.617694 accuracy: 0.670165\n",
      "[global_step-30000] duration: 95s train_loss: 0.617523 accuracy: 0.669991\n",
      "[global_step-30000] duration: 199s test_loss: 0.573094 accuracy: 0.723320\n",
      "[global_step-30500] duration: 95s train_loss: 0.617111 accuracy: 0.670560\n",
      "[global_step-31000] duration: 95s train_loss: 0.617020 accuracy: 0.670616\n",
      "[global_step-31500] duration: 95s train_loss: 0.616917 accuracy: 0.670497\n",
      "[global_step-32000] duration: 95s train_loss: 0.617042 accuracy: 0.670299\n",
      "[global_step-32500] duration: 89s train_loss: 0.616900 accuracy: 0.670509\n",
      "[global_step-33000] duration: 86s train_loss: 0.616740 accuracy: 0.670371\n",
      "[global_step-33500] duration: 95s train_loss: 0.616590 accuracy: 0.670358\n",
      "[global_step-34000] duration: 95s train_loss: 0.616615 accuracy: 0.670184\n",
      "[global_step-34500] duration: 95s train_loss: 0.616516 accuracy: 0.670181\n",
      "[global_step-35000] duration: 95s train_loss: 0.616272 accuracy: 0.670325\n",
      "[global_step-35000] duration: 199s test_loss: 0.572213 accuracy: 0.722273\n",
      "[global_step-35500] duration: 88s train_loss: 0.616264 accuracy: 0.670223\n",
      "[global_step-36000] duration: 87s train_loss: 0.616243 accuracy: 0.670264\n",
      "[global_step-36500] duration: 95s train_loss: 0.616160 accuracy: 0.670271\n",
      "[global_step-37000] duration: 95s train_loss: 0.616081 accuracy: 0.670220\n",
      "[global_step-37500] duration: 95s train_loss: 0.616109 accuracy: 0.669991\n",
      "[global_step-38000] duration: 95s train_loss: 0.616048 accuracy: 0.669911\n",
      "[global_step-38500] duration: 95s train_loss: 0.616130 accuracy: 0.669641\n",
      "[global_step-39000] duration: 89s train_loss: 0.616109 accuracy: 0.669618\n",
      "[global_step-39500] duration: 87s train_loss: 0.616178 accuracy: 0.669446\n",
      "[global_step-40000] duration: 95s train_loss: 0.616177 accuracy: 0.669291\n",
      "[global_step-40000] duration: 199s test_loss: 0.572313 accuracy: 0.721826\n",
      "[global_step-40500] duration: 95s train_loss: 0.616150 accuracy: 0.669209\n",
      "[global_step-41000] duration: 95s train_loss: 0.616114 accuracy: 0.669084\n",
      "[global_step-41500] duration: 95s train_loss: 0.616146 accuracy: 0.668963\n",
      "[global_step-42000] duration: 95s train_loss: 0.616134 accuracy: 0.668878\n",
      "[global_step-42500] duration: 95s train_loss: 0.616120 accuracy: 0.668905\n",
      "[global_step-43000] duration: 95s train_loss: 0.616056 accuracy: 0.668880\n",
      "[global_step-43500] duration: 94s train_loss: 0.615993 accuracy: 0.668846\n",
      "[global_step-44000] duration: 94s train_loss: 0.615968 accuracy: 0.668794\n",
      "[global_step-44500] duration: 95s train_loss: 0.615922 accuracy: 0.668806\n",
      "[global_step-45000] duration: 85s train_loss: 0.615915 accuracy: 0.668741\n",
      "[global_step-45000] duration: 194s test_loss: 0.571440 accuracy: 0.722350\n",
      "[global_step-45500] duration: 95s train_loss: 0.615910 accuracy: 0.668651\n",
      "[global_step-46000] duration: 95s train_loss: 0.615909 accuracy: 0.668616\n",
      "[global_step-46500] duration: 95s train_loss: 0.615833 accuracy: 0.668611\n",
      "[global_step-47000] duration: 95s train_loss: 0.615822 accuracy: 0.668545\n",
      "[global_step-47500] duration: 85s train_loss: 0.615810 accuracy: 0.668552\n",
      "[global_step-48000] duration: 90s train_loss: 0.615824 accuracy: 0.668496\n",
      "[global_step-48500] duration: 95s train_loss: 0.615765 accuracy: 0.668509\n",
      "[global_step-49000] duration: 95s train_loss: 0.615732 accuracy: 0.668422\n",
      "[global_step-49500] duration: 95s train_loss: 0.615711 accuracy: 0.668410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-50000] duration: 95s train_loss: 0.615697 accuracy: 0.668418\n",
      "[global_step-50000] duration: 198s test_loss: 0.570325 accuracy: 0.721239\n",
      "[global_step-50500] duration: 95s train_loss: 0.615665 accuracy: 0.668443\n",
      "[global_step-51000] duration: 93s train_loss: 0.615619 accuracy: 0.668448\n",
      "[global_step-51500] duration: 84s train_loss: 0.615626 accuracy: 0.668403\n",
      "[global_step-52000] duration: 93s train_loss: 0.615604 accuracy: 0.668374\n",
      "[global_step-52500] duration: 95s train_loss: 0.615597 accuracy: 0.668320\n",
      "[global_step-53000] duration: 95s train_loss: 0.615596 accuracy: 0.668266\n",
      "[global_step-53500] duration: 95s train_loss: 0.615556 accuracy: 0.668297\n",
      "[global_step-54000] duration: 95s train_loss: 0.615516 accuracy: 0.668252\n",
      "[global_step-54500] duration: 95s train_loss: 0.615494 accuracy: 0.668245\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l2_mto1_norm')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=200,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=2, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 2\n",
      "[global_step-500] duration: 95s train_loss: 0.649630 accuracy: 0.663703\n",
      "[global_step-1000] duration: 72s train_loss: 0.640857 accuracy: 0.668858\n",
      "[global_step-1500] duration: 83s train_loss: 0.638091 accuracy: 0.670484\n",
      "[global_step-2000] duration: 83s train_loss: 0.636243 accuracy: 0.671937\n",
      "[global_step-2500] duration: 83s train_loss: 0.635260 accuracy: 0.672645\n",
      "[global_step-3000] duration: 83s train_loss: 0.634807 accuracy: 0.672712\n",
      "[global_step-3500] duration: 83s train_loss: 0.634532 accuracy: 0.672805\n",
      "[global_step-4000] duration: 83s train_loss: 0.634179 accuracy: 0.673040\n",
      "[global_step-4500] duration: 83s train_loss: 0.633906 accuracy: 0.673176\n",
      "[global_step-5000] duration: 83s train_loss: 0.633706 accuracy: 0.673259\n",
      "[global_step-5000] duration: 145s test_loss: 0.597569 accuracy: 0.723569\n",
      "Saving model...\n",
      "[global_step-5500] duration: 72s train_loss: 0.633476 accuracy: 0.673414\n",
      "[global_step-6000] duration: 81s train_loss: 0.633297 accuracy: 0.673531\n",
      "[global_step-6500] duration: 83s train_loss: 0.633207 accuracy: 0.673589\n",
      "[global_step-7000] duration: 83s train_loss: 0.633079 accuracy: 0.673637\n",
      "[global_step-7500] duration: 83s train_loss: 0.633082 accuracy: 0.673548\n",
      "[global_step-8000] duration: 83s train_loss: 0.632991 accuracy: 0.673583\n",
      "[global_step-8500] duration: 83s train_loss: 0.632907 accuracy: 0.673653\n",
      "[global_step-9000] duration: 83s train_loss: 0.632878 accuracy: 0.673624\n",
      "[global_step-9500] duration: 83s train_loss: 0.632773 accuracy: 0.673735\n",
      "[global_step-10000] duration: 83s train_loss: 0.632513 accuracy: 0.674007\n",
      "[global_step-10000] duration: 137s test_loss: 0.601228 accuracy: 0.723337\n",
      "[global_step-10500] duration: 78s train_loss: 0.632475 accuracy: 0.673963\n",
      "[global_step-11000] duration: 83s train_loss: 0.632336 accuracy: 0.674063\n",
      "[global_step-11500] duration: 83s train_loss: 0.632333 accuracy: 0.673991\n",
      "[global_step-12000] duration: 83s train_loss: 0.632213 accuracy: 0.674097\n",
      "[global_step-12500] duration: 83s train_loss: 0.632202 accuracy: 0.674052\n",
      "[global_step-13000] duration: 83s train_loss: 0.632248 accuracy: 0.673954\n",
      "[global_step-13500] duration: 83s train_loss: 0.632207 accuracy: 0.673966\n",
      "[global_step-14000] duration: 83s train_loss: 0.632236 accuracy: 0.673888\n",
      "[global_step-14500] duration: 83s train_loss: 0.632123 accuracy: 0.674006\n",
      "[global_step-15000] duration: 81s train_loss: 0.632075 accuracy: 0.674034\n",
      "[global_step-15000] duration: 134s test_loss: 0.590632 accuracy: 0.723242\n",
      "[global_step-15500] duration: 83s train_loss: 0.632046 accuracy: 0.674035\n",
      "[global_step-16000] duration: 83s train_loss: 0.632055 accuracy: 0.673985\n",
      "[global_step-16500] duration: 83s train_loss: 0.632001 accuracy: 0.674046\n",
      "[global_step-17000] duration: 83s train_loss: 0.631959 accuracy: 0.674069\n",
      "[global_step-17500] duration: 83s train_loss: 0.631897 accuracy: 0.674126\n",
      "[global_step-18000] duration: 83s train_loss: 0.631840 accuracy: 0.674167\n",
      "[global_step-18500] duration: 83s train_loss: 0.631857 accuracy: 0.674098\n",
      "[global_step-19000] duration: 83s train_loss: 0.631826 accuracy: 0.674120\n",
      "[global_step-19500] duration: 83s train_loss: 0.631826 accuracy: 0.674090\n",
      "[global_step-20000] duration: 72s train_loss: 0.631789 accuracy: 0.674110\n",
      "[global_step-20000] duration: 142s test_loss: 0.597268 accuracy: 0.723574\n",
      "Saving model...\n",
      "[global_step-20500] duration: 83s train_loss: 0.631765 accuracy: 0.674112\n",
      "[global_step-21000] duration: 83s train_loss: 0.631752 accuracy: 0.674108\n",
      "[global_step-21500] duration: 83s train_loss: 0.631757 accuracy: 0.674077\n",
      "[global_step-22000] duration: 83s train_loss: 0.631676 accuracy: 0.674169\n",
      "[global_step-22500] duration: 83s train_loss: 0.631674 accuracy: 0.674153\n",
      "[global_step-23000] duration: 83s train_loss: 0.631660 accuracy: 0.674157\n",
      "[global_step-23500] duration: 83s train_loss: 0.631641 accuracy: 0.674154\n",
      "[global_step-24000] duration: 83s train_loss: 0.631596 accuracy: 0.674189\n",
      "[global_step-24500] duration: 75s train_loss: 0.631589 accuracy: 0.674171\n",
      "[global_step-25000] duration: 73s train_loss: 0.631565 accuracy: 0.674183\n",
      "[global_step-25000] duration: 149s test_loss: 0.596491 accuracy: 0.722732\n",
      "[global_step-25500] duration: 83s train_loss: 0.631583 accuracy: 0.674145\n",
      "[global_step-26000] duration: 83s train_loss: 0.631583 accuracy: 0.674123\n",
      "[global_step-26500] duration: 83s train_loss: 0.631600 accuracy: 0.674085\n",
      "[global_step-27000] duration: 83s train_loss: 0.631611 accuracy: 0.674045\n",
      "[global_step-27500] duration: 136s train_loss: 0.628808 accuracy: 0.678242\n",
      "[global_step-28000] duration: 83s train_loss: 0.631002 accuracy: 0.674100\n",
      "[global_step-28500] duration: 81s train_loss: 0.630560 accuracy: 0.674531\n",
      "[global_step-29000] duration: 72s train_loss: 0.630676 accuracy: 0.674400\n",
      "[global_step-29500] duration: 77s train_loss: 0.630867 accuracy: 0.674136\n",
      "[global_step-30000] duration: 82s train_loss: 0.630803 accuracy: 0.674192\n",
      "[global_step-30000] duration: 152s test_loss: 0.590305 accuracy: 0.723319\n",
      "[global_step-30500] duration: 82s train_loss: 0.630885 accuracy: 0.674100\n",
      "[global_step-31000] duration: 83s train_loss: 0.630773 accuracy: 0.674208\n",
      "[global_step-31500] duration: 83s train_loss: 0.630714 accuracy: 0.674274\n",
      "[global_step-32000] duration: 82s train_loss: 0.630633 accuracy: 0.674381\n",
      "[global_step-32500] duration: 82s train_loss: 0.630662 accuracy: 0.674333\n",
      "[global_step-33000] duration: 83s train_loss: 0.630730 accuracy: 0.674183\n",
      "[global_step-33500] duration: 73s train_loss: 0.630894 accuracy: 0.673962\n",
      "[global_step-34000] duration: 75s train_loss: 0.630941 accuracy: 0.673914\n",
      "[global_step-34500] duration: 83s train_loss: 0.630961 accuracy: 0.673938\n",
      "[global_step-35000] duration: 83s train_loss: 0.631017 accuracy: 0.673854\n",
      "[global_step-35000] duration: 149s test_loss: 0.592678 accuracy: 0.723462\n",
      "[global_step-35500] duration: 83s train_loss: 0.631035 accuracy: 0.673864\n",
      "[global_step-36000] duration: 83s train_loss: 0.631054 accuracy: 0.673835\n",
      "[global_step-36500] duration: 83s train_loss: 0.631111 accuracy: 0.673733\n",
      "[global_step-37000] duration: 83s train_loss: 0.631074 accuracy: 0.673795\n",
      "[global_step-37500] duration: 83s train_loss: 0.631098 accuracy: 0.673757\n",
      "[global_step-38000] duration: 75s train_loss: 0.630996 accuracy: 0.673878\n",
      "[global_step-38500] duration: 73s train_loss: 0.631017 accuracy: 0.673834\n",
      "[global_step-39000] duration: 83s train_loss: 0.631044 accuracy: 0.673768\n",
      "[global_step-39500] duration: 83s train_loss: 0.631081 accuracy: 0.673709\n",
      "[global_step-40000] duration: 83s train_loss: 0.631094 accuracy: 0.673679\n",
      "[global_step-40000] duration: 149s test_loss: 0.589692 accuracy: 0.722865\n",
      "[global_step-40500] duration: 83s train_loss: 0.631123 accuracy: 0.673632\n",
      "[global_step-41000] duration: 83s train_loss: 0.631124 accuracy: 0.673661\n",
      "[global_step-41500] duration: 83s train_loss: 0.631171 accuracy: 0.673591\n",
      "[global_step-42000] duration: 83s train_loss: 0.631101 accuracy: 0.673685\n",
      "[global_step-42500] duration: 78s train_loss: 0.631101 accuracy: 0.673690\n",
      "[global_step-43000] duration: 72s train_loss: 0.631050 accuracy: 0.673730\n",
      "[global_step-43500] duration: 81s train_loss: 0.630957 accuracy: 0.673867\n",
      "[global_step-44000] duration: 83s train_loss: 0.630948 accuracy: 0.673875\n",
      "[global_step-44500] duration: 83s train_loss: 0.630889 accuracy: 0.673958\n",
      "[global_step-45000] duration: 83s train_loss: 0.630890 accuracy: 0.673950\n",
      "[global_step-45000] duration: 149s test_loss: 0.591885 accuracy: 0.723427\n",
      "[global_step-45500] duration: 83s train_loss: 0.630881 accuracy: 0.673970\n",
      "[global_step-46000] duration: 83s train_loss: 0.630893 accuracy: 0.673963\n",
      "[global_step-46500] duration: 82s train_loss: 0.630862 accuracy: 0.674008\n",
      "[global_step-47000] duration: 80s train_loss: 0.630793 accuracy: 0.674098\n",
      "[global_step-47500] duration: 72s train_loss: 0.630793 accuracy: 0.674112\n",
      "[global_step-48000] duration: 79s train_loss: 0.630777 accuracy: 0.674144\n",
      "[global_step-48500] duration: 83s train_loss: 0.630753 accuracy: 0.674180\n",
      "[global_step-49000] duration: 83s train_loss: 0.630780 accuracy: 0.674141\n",
      "[global_step-49500] duration: 83s train_loss: 0.630780 accuracy: 0.674147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-50000] duration: 83s train_loss: 0.630769 accuracy: 0.674165\n",
      "[global_step-50000] duration: 149s test_loss: 0.593760 accuracy: 0.723284\n",
      "[global_step-50500] duration: 83s train_loss: 0.630754 accuracy: 0.674187\n",
      "[global_step-51000] duration: 83s train_loss: 0.630756 accuracy: 0.674186\n",
      "[global_step-51500] duration: 82s train_loss: 0.630747 accuracy: 0.674202\n",
      "[global_step-52000] duration: 72s train_loss: 0.630762 accuracy: 0.674176\n",
      "[global_step-52500] duration: 76s train_loss: 0.630762 accuracy: 0.674176\n",
      "[global_step-53000] duration: 83s train_loss: 0.630718 accuracy: 0.674240\n",
      "[global_step-53500] duration: 83s train_loss: 0.630690 accuracy: 0.674274\n",
      "[global_step-54000] duration: 83s train_loss: 0.630655 accuracy: 0.674325\n",
      "[global_step-54500] duration: 83s train_loss: 0.630634 accuracy: 0.674346\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l2_mto1')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=200,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=2, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 3\n",
      "[global_step-500] duration: 104s train_loss: 0.653550 accuracy: 0.660626\n",
      "[global_step-1000] duration: 85s train_loss: 0.643433 accuracy: 0.668046\n",
      "[global_step-1500] duration: 81s train_loss: 0.640464 accuracy: 0.669832\n",
      "[global_step-2000] duration: 73s train_loss: 0.638996 accuracy: 0.670654\n",
      "[global_step-2500] duration: 82s train_loss: 0.637734 accuracy: 0.671423\n",
      "[global_step-3000] duration: 85s train_loss: 0.636524 accuracy: 0.672615\n",
      "[global_step-3500] duration: 85s train_loss: 0.636364 accuracy: 0.672365\n",
      "[global_step-4000] duration: 85s train_loss: 0.636234 accuracy: 0.672246\n",
      "[global_step-4500] duration: 85s train_loss: 0.635810 accuracy: 0.672471\n",
      "[global_step-5000] duration: 85s train_loss: 0.635486 accuracy: 0.672576\n",
      "[global_step-5000] duration: 283s test_loss: 0.597728 accuracy: 0.722904\n",
      "Saving model...\n",
      "[global_step-5500] duration: 73s train_loss: 0.635120 accuracy: 0.672751\n",
      "[global_step-6000] duration: 78s train_loss: 0.634966 accuracy: 0.672724\n",
      "[global_step-6500] duration: 85s train_loss: 0.634705 accuracy: 0.672821\n",
      "[global_step-7000] duration: 85s train_loss: 0.634384 accuracy: 0.673079\n",
      "[global_step-7500] duration: 85s train_loss: 0.634276 accuracy: 0.673102\n",
      "[global_step-8000] duration: 85s train_loss: 0.634153 accuracy: 0.673088\n",
      "[global_step-8500] duration: 85s train_loss: 0.633921 accuracy: 0.673324\n",
      "[global_step-9000] duration: 85s train_loss: 0.633954 accuracy: 0.673204\n",
      "[global_step-9500] duration: 85s train_loss: 0.633740 accuracy: 0.673402\n",
      "[global_step-10000] duration: 85s train_loss: 0.633674 accuracy: 0.673404\n",
      "[global_step-10000] duration: 262s test_loss: 0.590441 accuracy: 0.723345\n",
      "Saving model...\n",
      "[global_step-10500] duration: 85s train_loss: 0.633615 accuracy: 0.673372\n",
      "[global_step-11000] duration: 85s train_loss: 0.633510 accuracy: 0.673449\n",
      "[global_step-11500] duration: 85s train_loss: 0.633376 accuracy: 0.673524\n",
      "[global_step-12000] duration: 85s train_loss: 0.633399 accuracy: 0.673411\n",
      "[global_step-12500] duration: 85s train_loss: 0.633349 accuracy: 0.673381\n",
      "[global_step-13000] duration: 85s train_loss: 0.633298 accuracy: 0.673387\n",
      "[global_step-13500] duration: 85s train_loss: 0.633356 accuracy: 0.673253\n",
      "[global_step-14000] duration: 85s train_loss: 0.633201 accuracy: 0.673412\n",
      "[global_step-14500] duration: 76s train_loss: 0.633177 accuracy: 0.673376\n",
      "[global_step-15000] duration: 75s train_loss: 0.633066 accuracy: 0.673483\n",
      "[global_step-15000] duration: 294s test_loss: 0.599944 accuracy: 0.723125\n",
      "[global_step-15500] duration: 84s train_loss: 0.633036 accuracy: 0.673454\n",
      "[global_step-16000] duration: 85s train_loss: 0.633053 accuracy: 0.673395\n",
      "[global_step-16500] duration: 84s train_loss: 0.632971 accuracy: 0.673468\n",
      "[global_step-17000] duration: 84s train_loss: 0.632963 accuracy: 0.673457\n",
      "[global_step-17500] duration: 84s train_loss: 0.632871 accuracy: 0.673518\n",
      "[global_step-18000] duration: 80s train_loss: 0.632851 accuracy: 0.673502\n",
      "[global_step-18500] duration: 73s train_loss: 0.632836 accuracy: 0.673500\n",
      "[global_step-19000] duration: 82s train_loss: 0.632785 accuracy: 0.673540\n",
      "[global_step-19500] duration: 84s train_loss: 0.632802 accuracy: 0.673485\n",
      "[global_step-20000] duration: 84s train_loss: 0.632762 accuracy: 0.673505\n",
      "[global_step-20000] duration: 293s test_loss: 0.589893 accuracy: 0.722756\n",
      "[global_step-20500] duration: 85s train_loss: 0.632694 accuracy: 0.673575\n",
      "[global_step-21000] duration: 85s train_loss: 0.632608 accuracy: 0.673670\n",
      "[global_step-21500] duration: 84s train_loss: 0.632607 accuracy: 0.673647\n",
      "[global_step-22000] duration: 73s train_loss: 0.632510 accuracy: 0.673743\n",
      "[global_step-22500] duration: 78s train_loss: 0.632444 accuracy: 0.673809\n",
      "[global_step-23000] duration: 85s train_loss: 0.632407 accuracy: 0.673839\n",
      "[global_step-23500] duration: 85s train_loss: 0.632372 accuracy: 0.673869\n",
      "[global_step-24000] duration: 85s train_loss: 0.632369 accuracy: 0.673846\n",
      "[global_step-24500] duration: 85s train_loss: 0.632353 accuracy: 0.673855\n",
      "[global_step-25000] duration: 85s train_loss: 0.632362 accuracy: 0.673823\n",
      "[global_step-25000] duration: 297s test_loss: 0.596019 accuracy: 0.723534\n",
      "Saving model...\n",
      "[global_step-25500] duration: 76s train_loss: 0.632298 accuracy: 0.673902\n",
      "[global_step-26000] duration: 76s train_loss: 0.632246 accuracy: 0.673956\n",
      "[global_step-26500] duration: 85s train_loss: 0.632218 accuracy: 0.673984\n",
      "[global_step-27000] duration: 85s train_loss: 0.632179 accuracy: 0.674017\n",
      "[global_step-27500] duration: 85s train_loss: 0.632229 accuracy: 0.673925\n",
      "[global_step-28000] duration: 85s train_loss: 0.632201 accuracy: 0.673952\n",
      "[global_step-28500] duration: 85s train_loss: 0.632229 accuracy: 0.673901\n",
      "[global_step-29000] duration: 85s train_loss: 0.632237 accuracy: 0.673865\n",
      "[global_step-29500] duration: 85s train_loss: 0.632183 accuracy: 0.673926\n",
      "[global_step-30000] duration: 85s train_loss: 0.632215 accuracy: 0.673867\n",
      "[global_step-30000] duration: 275s test_loss: 0.597986 accuracy: 0.723364\n",
      "[global_step-30500] duration: 85s train_loss: 0.632179 accuracy: 0.673907\n",
      "[global_step-31000] duration: 85s train_loss: 0.632177 accuracy: 0.673902\n",
      "[global_step-31500] duration: 85s train_loss: 0.632193 accuracy: 0.673872\n",
      "[global_step-32000] duration: 85s train_loss: 0.632214 accuracy: 0.673836\n",
      "[global_step-32500] duration: 84s train_loss: 0.632188 accuracy: 0.673872\n",
      "[global_step-33000] duration: 84s train_loss: 0.632181 accuracy: 0.673873\n",
      "[global_step-33500] duration: 85s train_loss: 0.632176 accuracy: 0.673865\n",
      "[global_step-34000] duration: 85s train_loss: 0.632183 accuracy: 0.673851\n",
      "[global_step-34500] duration: 77s train_loss: 0.632160 accuracy: 0.673867\n",
      "[global_step-35000] duration: 74s train_loss: 0.632151 accuracy: 0.673874\n",
      "[global_step-35000] duration: 293s test_loss: 0.595976 accuracy: 0.723526\n",
      "[global_step-35500] duration: 85s train_loss: 0.632169 accuracy: 0.673837\n",
      "[global_step-36000] duration: 85s train_loss: 0.632161 accuracy: 0.673843\n",
      "[global_step-36500] duration: 85s train_loss: 0.632138 accuracy: 0.673856\n",
      "[global_step-37000] duration: 85s train_loss: 0.632121 accuracy: 0.673865\n",
      "[global_step-37500] duration: 85s train_loss: 0.632116 accuracy: 0.673865\n",
      "[global_step-38000] duration: 81s train_loss: 0.632074 accuracy: 0.673918\n",
      "[global_step-38500] duration: 74s train_loss: 0.632046 accuracy: 0.673940\n",
      "[global_step-39000] duration: 82s train_loss: 0.632039 accuracy: 0.673940\n",
      "[global_step-39500] duration: 85s train_loss: 0.632045 accuracy: 0.673919\n",
      "[global_step-40000] duration: 85s train_loss: 0.632022 accuracy: 0.673941\n",
      "[global_step-40000] duration: 295s test_loss: 0.592440 accuracy: 0.723037\n",
      "[global_step-40500] duration: 85s train_loss: 0.632014 accuracy: 0.673944\n",
      "[global_step-41000] duration: 85s train_loss: 0.631983 accuracy: 0.673981\n",
      "[global_step-41500] duration: 84s train_loss: 0.631929 accuracy: 0.674039\n",
      "[global_step-42000] duration: 73s train_loss: 0.631904 accuracy: 0.674069\n",
      "[global_step-42500] duration: 79s train_loss: 0.631910 accuracy: 0.674056\n",
      "[global_step-43000] duration: 85s train_loss: 0.631877 accuracy: 0.674094\n",
      "[global_step-43500] duration: 84s train_loss: 0.631867 accuracy: 0.674099\n",
      "[global_step-44000] duration: 85s train_loss: 0.631864 accuracy: 0.674102\n",
      "[global_step-44500] duration: 85s train_loss: 0.631844 accuracy: 0.674124\n",
      "[global_step-45000] duration: 85s train_loss: 0.631827 accuracy: 0.674145\n",
      "[global_step-45000] duration: 262s test_loss: 0.596073 accuracy: 0.723080\n",
      "[global_step-45500] duration: 85s train_loss: 0.631834 accuracy: 0.674125\n",
      "[global_step-46000] duration: 85s train_loss: 0.631826 accuracy: 0.674134\n",
      "[global_step-46500] duration: 85s train_loss: 0.631841 accuracy: 0.674107\n",
      "[global_step-47000] duration: 85s train_loss: 0.631864 accuracy: 0.674070\n",
      "[global_step-47500] duration: 85s train_loss: 0.631845 accuracy: 0.674091\n",
      "[global_step-48000] duration: 85s train_loss: 0.631857 accuracy: 0.674063\n",
      "[global_step-48500] duration: 85s train_loss: 0.631850 accuracy: 0.674074\n",
      "[global_step-49000] duration: 85s train_loss: 0.631843 accuracy: 0.674082\n",
      "[global_step-49500] duration: 85s train_loss: 0.631834 accuracy: 0.674090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-50000] duration: 85s train_loss: 0.631819 accuracy: 0.674103\n",
      "[global_step-50000] duration: 262s test_loss: 0.591589 accuracy: 0.723534\n",
      "[global_step-50500] duration: 85s train_loss: 0.631795 accuracy: 0.674132\n",
      "[global_step-51000] duration: 85s train_loss: 0.631749 accuracy: 0.674179\n",
      "[global_step-51500] duration: 85s train_loss: 0.631737 accuracy: 0.674193\n",
      "[global_step-52000] duration: 85s train_loss: 0.631719 accuracy: 0.674207\n",
      "[global_step-52500] duration: 85s train_loss: 0.631693 accuracy: 0.674239\n",
      "[global_step-53000] duration: 85s train_loss: 0.631666 accuracy: 0.674270\n",
      "[global_step-53500] duration: 85s train_loss: 0.631672 accuracy: 0.674258\n",
      "[global_step-54000] duration: 85s train_loss: 0.631662 accuracy: 0.674265\n",
      "[global_step-54500] duration: 81s train_loss: 0.631686 accuracy: 0.674232\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l3_mto1')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=3, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 5497332, 5497332\n",
      "Label Range: {0: [-30, 0], 1: [0, 31]}\n",
      "Loading stock data by compnay name\n",
      "Number of data: 433086, 433086\n",
      "Label Length: 2\n",
      "Num of layers: 4\n",
      "[global_step-500] duration: 135s train_loss: 0.656101 accuracy: 0.661997\n",
      "[global_step-1000] duration: 115s train_loss: 0.643816 accuracy: 0.670344\n",
      "[global_step-1500] duration: 115s train_loss: 0.640710 accuracy: 0.671392\n",
      "[global_step-2000] duration: 115s train_loss: 0.638689 accuracy: 0.672493\n",
      "[global_step-2500] duration: 115s train_loss: 0.637342 accuracy: 0.673267\n",
      "[global_step-3000] duration: 114s train_loss: 0.636571 accuracy: 0.673589\n",
      "[global_step-3500] duration: 99s train_loss: 0.635650 accuracy: 0.674212\n",
      "[global_step-4000] duration: 112s train_loss: 0.634890 accuracy: 0.674778\n",
      "[global_step-4500] duration: 115s train_loss: 0.634632 accuracy: 0.674753\n",
      "[global_step-5000] duration: 114s train_loss: 0.634532 accuracy: 0.674684\n",
      "[global_step-5000] duration: 365s test_loss: 0.597557 accuracy: 0.723427\n",
      "Saving model...\n",
      "[global_step-5500] duration: 111s train_loss: 0.634549 accuracy: 0.674424\n",
      "[global_step-6000] duration: 100s train_loss: 0.634353 accuracy: 0.674317\n",
      "[global_step-6500] duration: 115s train_loss: 0.634348 accuracy: 0.674116\n",
      "[global_step-7000] duration: 115s train_loss: 0.634052 accuracy: 0.674326\n",
      "[global_step-7500] duration: 115s train_loss: 0.633894 accuracy: 0.674374\n",
      "[global_step-8000] duration: 115s train_loss: 0.633862 accuracy: 0.674251\n",
      "[global_step-8500] duration: 115s train_loss: 0.633741 accuracy: 0.674288\n",
      "[global_step-9000] duration: 115s train_loss: 0.633647 accuracy: 0.674289\n",
      "[global_step-9500] duration: 110s train_loss: 0.633582 accuracy: 0.674266\n",
      "[global_step-10000] duration: 100s train_loss: 0.633524 accuracy: 0.674238\n",
      "[global_step-10000] duration: 364s test_loss: 0.604695 accuracy: 0.721259\n",
      "[global_step-10500] duration: 115s train_loss: 0.633460 accuracy: 0.674232\n",
      "[global_step-11000] duration: 115s train_loss: 0.633503 accuracy: 0.674060\n",
      "[global_step-11500] duration: 115s train_loss: 0.633345 accuracy: 0.674157\n",
      "[global_step-12000] duration: 107s train_loss: 0.633246 accuracy: 0.674235\n",
      "[global_step-12500] duration: 103s train_loss: 0.633185 accuracy: 0.674237\n",
      "[global_step-13000] duration: 115s train_loss: 0.633152 accuracy: 0.674226\n",
      "[global_step-13500] duration: 115s train_loss: 0.633014 accuracy: 0.674355\n",
      "[global_step-14000] duration: 115s train_loss: 0.633112 accuracy: 0.674183\n",
      "[global_step-14500] duration: 115s train_loss: 0.633056 accuracy: 0.674180\n",
      "[global_step-15000] duration: 115s train_loss: 0.632978 accuracy: 0.674216\n",
      "[global_step-15000] duration: 347s test_loss: 0.590860 accuracy: 0.723534\n",
      "Saving model...\n",
      "[global_step-15500] duration: 115s train_loss: 0.632981 accuracy: 0.674163\n",
      "[global_step-16000] duration: 114s train_loss: 0.632868 accuracy: 0.674255\n",
      "[global_step-16500] duration: 115s train_loss: 0.632839 accuracy: 0.674227\n",
      "[global_step-17000] duration: 115s train_loss: 0.632768 accuracy: 0.674264\n",
      "[global_step-17500] duration: 115s train_loss: 0.632797 accuracy: 0.674204\n",
      "[global_step-18000] duration: 115s train_loss: 0.632778 accuracy: 0.674208\n",
      "[global_step-18500] duration: 104s train_loss: 0.632789 accuracy: 0.674188\n",
      "[global_step-19000] duration: 107s train_loss: 0.632819 accuracy: 0.674123\n",
      "[global_step-19500] duration: 115s train_loss: 0.632810 accuracy: 0.674111\n",
      "[global_step-20000] duration: 115s train_loss: 0.632797 accuracy: 0.674100\n",
      "[global_step-20000] duration: 365s test_loss: 0.601333 accuracy: 0.723534\n",
      "[global_step-20500] duration: 115s train_loss: 0.632770 accuracy: 0.674116\n",
      "[global_step-21000] duration: 101s train_loss: 0.632759 accuracy: 0.674112\n",
      "[global_step-21500] duration: 110s train_loss: 0.632746 accuracy: 0.674109\n",
      "[global_step-22000] duration: 115s train_loss: 0.632704 accuracy: 0.674150\n",
      "[global_step-22500] duration: 115s train_loss: 0.632659 accuracy: 0.674196\n",
      "[global_step-23000] duration: 115s train_loss: 0.632653 accuracy: 0.674180\n",
      "[global_step-23500] duration: 115s train_loss: 0.632675 accuracy: 0.674152\n",
      "[global_step-24000] duration: 115s train_loss: 0.632720 accuracy: 0.674080\n",
      "[global_step-24500] duration: 115s train_loss: 0.632760 accuracy: 0.674016\n",
      "[global_step-25000] duration: 100s train_loss: 0.632711 accuracy: 0.674061\n",
      "[global_step-25000] duration: 360s test_loss: 0.593946 accuracy: 0.723085\n",
      "[global_step-25500] duration: 115s train_loss: 0.632727 accuracy: 0.674014\n",
      "[global_step-26000] duration: 115s train_loss: 0.632732 accuracy: 0.673996\n",
      "[global_step-26500] duration: 108s train_loss: 0.632683 accuracy: 0.674039\n",
      "[global_step-27000] duration: 103s train_loss: 0.632654 accuracy: 0.674067\n",
      "[global_step-27500] duration: 115s train_loss: 0.632669 accuracy: 0.674031\n",
      "[global_step-28000] duration: 115s train_loss: 0.632608 accuracy: 0.674089\n",
      "[global_step-28500] duration: 115s train_loss: 0.632616 accuracy: 0.674074\n",
      "[global_step-29000] duration: 115s train_loss: 0.632586 accuracy: 0.674106\n",
      "[global_step-29500] duration: 115s train_loss: 0.632599 accuracy: 0.674079\n",
      "[global_step-30000] duration: 108s train_loss: 0.632573 accuracy: 0.674100\n",
      "[global_step-30000] duration: 354s test_loss: 0.597565 accuracy: 0.722639\n",
      "[global_step-30500] duration: 115s train_loss: 0.632546 accuracy: 0.674129\n",
      "[global_step-31000] duration: 115s train_loss: 0.632551 accuracy: 0.674100\n",
      "[global_step-31500] duration: 115s train_loss: 0.632535 accuracy: 0.674120\n",
      "[global_step-32000] duration: 115s train_loss: 0.632532 accuracy: 0.674119\n",
      "[global_step-32500] duration: 113s train_loss: 0.632592 accuracy: 0.674028\n",
      "[global_step-33000] duration: 99s train_loss: 0.632605 accuracy: 0.674005\n",
      "[global_step-33500] duration: 113s train_loss: 0.632600 accuracy: 0.674006\n",
      "[global_step-34000] duration: 114s train_loss: 0.632603 accuracy: 0.673990\n",
      "[global_step-34500] duration: 114s train_loss: 0.632565 accuracy: 0.674031\n",
      "[global_step-35000] duration: 115s train_loss: 0.632563 accuracy: 0.674027\n",
      "[global_step-35000] duration: 365s test_loss: 0.600846 accuracy: 0.722906\n",
      "[global_step-35500] duration: 112s train_loss: 0.632551 accuracy: 0.674025\n",
      "[global_step-36000] duration: 99s train_loss: 0.632564 accuracy: 0.674006\n",
      "[global_step-36500] duration: 114s train_loss: 0.632501 accuracy: 0.674084\n",
      "[global_step-37000] duration: 115s train_loss: 0.632475 accuracy: 0.674112\n",
      "[global_step-37500] duration: 115s train_loss: 0.632475 accuracy: 0.674111\n",
      "[global_step-38000] duration: 115s train_loss: 0.632488 accuracy: 0.674094\n",
      "[global_step-38500] duration: 115s train_loss: 0.632458 accuracy: 0.674131\n",
      "[global_step-39000] duration: 115s train_loss: 0.632449 accuracy: 0.674145\n",
      "[global_step-39500] duration: 115s train_loss: 0.632432 accuracy: 0.674164\n",
      "[global_step-40000] duration: 105s train_loss: 0.632386 accuracy: 0.674216\n",
      "[global_step-40000] duration: 356s test_loss: 0.600502 accuracy: 0.723534\n",
      "[global_step-40500] duration: 115s train_loss: 0.632373 accuracy: 0.674224\n",
      "[global_step-41000] duration: 115s train_loss: 0.632386 accuracy: 0.674202\n",
      "[global_step-41500] duration: 115s train_loss: 0.632360 accuracy: 0.674238\n",
      "[global_step-42000] duration: 115s train_loss: 0.632328 accuracy: 0.674275\n",
      "[global_step-42500] duration: 108s train_loss: 0.632321 accuracy: 0.674286\n",
      "[global_step-43000] duration: 102s train_loss: 0.632346 accuracy: 0.674252\n",
      "[global_step-43500] duration: 115s train_loss: 0.632349 accuracy: 0.674251\n",
      "[global_step-44000] duration: 115s train_loss: 0.632338 accuracy: 0.674264\n",
      "[global_step-44500] duration: 115s train_loss: 0.632335 accuracy: 0.674267\n",
      "[global_step-45000] duration: 115s train_loss: 0.632327 accuracy: 0.674271\n",
      "[global_step-45000] duration: 364s test_loss: 0.602848 accuracy: 0.722658\n",
      "[global_step-45500] duration: 113s train_loss: 0.632320 accuracy: 0.674279\n",
      "[global_step-46000] duration: 99s train_loss: 0.632338 accuracy: 0.674249\n",
      "[global_step-46500] duration: 113s train_loss: 0.632336 accuracy: 0.674250\n",
      "[global_step-47000] duration: 115s train_loss: 0.632340 accuracy: 0.674243\n",
      "[global_step-47500] duration: 115s train_loss: 0.632319 accuracy: 0.674279\n",
      "[global_step-48000] duration: 115s train_loss: 0.632301 accuracy: 0.674299\n",
      "[global_step-48500] duration: 105s train_loss: 0.632294 accuracy: 0.674308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global_step-49000] duration: 106s train_loss: 0.632301 accuracy: 0.674288\n",
      "[global_step-49500] duration: 115s train_loss: 0.632300 accuracy: 0.674285\n",
      "[global_step-50000] duration: 115s train_loss: 0.632318 accuracy: 0.674261\n",
      "[global_step-50000] duration: 365s test_loss: 0.597690 accuracy: 0.723534\n",
      "[global_step-50500] duration: 115s train_loss: 0.632313 accuracy: 0.674272\n",
      "[global_step-51000] duration: 115s train_loss: 0.632325 accuracy: 0.674257\n",
      "[global_step-51500] duration: 115s train_loss: 0.632296 accuracy: 0.674293\n",
      "[global_step-52000] duration: 110s train_loss: 0.632301 accuracy: 0.674291\n",
      "[global_step-52500] duration: 101s train_loss: 0.632309 accuracy: 0.674277\n",
      "[global_step-53000] duration: 115s train_loss: 0.632287 accuracy: 0.674300\n",
      "[global_step-53500] duration: 115s train_loss: 0.632279 accuracy: 0.674310\n",
      "[global_step-54000] duration: 115s train_loss: 0.632287 accuracy: 0.674292\n",
      "[global_step-54500] duration: 115s train_loss: 0.632282 accuracy: 0.674298\n",
      "Early stopped !\n"
     ]
    }
   ],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l4_mto1')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=10, learning_rate=0.001, num_layers=4, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to one with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mto1_norm_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mto1_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l1_mto1_norm_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l1_mto1_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l2_mto1_norm_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=2, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all + concat with last outputs\n",
    "output_path = join(opath_root, '20seq_model_2017_h400_lr001_l2_mto1_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=2, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=400, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=2, data_status=1, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to many basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mtom_norm')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=0, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=1)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mtom')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=0, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=-1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=2, normalize=False)\n",
    "sp2.training(data_path=data_path, test_path=test_path, model_name='rnn', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to many with attention (Currently Not Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'd:/myai/data/20seq_data_2017/labelled_data_0'\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mtom_norm_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=0, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=2)\n",
    "sp2.training(data_path=data_path, model_name='rnn_new', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'd:/myai/data/20seq_data_2017/labelled_data_0'\n",
    "output_path = join(opath_root, '20seq_model_2017_h200_lr001_l1_mtom_attn')\n",
    "hparams = HParams(use_gpu=True, rnn_type='gru', mode=0, epochs=100, batch_size=100,\n",
    "                  feature_length=35, attention_type=1, sequence_length=20, use_bidirectional=True, dim_hidden=200, \n",
    "                  label_term=30, learning_rate=0.001, num_layers=1, data_status=2, normalize=False)\n",
    "sp2.training(data_path=data_path, model_name='rnn_new', output_path=output_path, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
